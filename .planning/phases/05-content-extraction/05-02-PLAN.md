---
phase: 05-content-extraction
plan: 02
depends_on: ["05-01"]
files_modified:
  - src/tools/extract-batch.ts
  - package.json
---

# Plan 05-02: Batch Extraction Pipeline

## Objective

Build `src/tools/extract-batch.ts` — a CLI tool that processes the translation queue in batch, extracting all (or a subset of) German servicePages from Sanity and writing individual JSON files to `src/data/extracted/`. This is the production workhorse that processes 587 pages reliably.

## Execution Context

```yaml
strategy: A  # Fully autonomous, no checkpoints
estimated_tasks: 2
estimated_minutes: 20
parallel_safe: true  # Independent from 05-03
```

## Context

### Dependencies

- **05-01** provides: `extractPage(germanId)` function, `ExtractedPage` type
- **Phase 4** provides: `src/data/translation-queue.json` (587 entries with germanId, slug, depth)

### Rate Limiting Considerations

- Sanity API has rate limits (varies by plan, typically 25-50 req/s for paid plans)
- 587 pages × 1 GROQ query per page = 587 API calls
- At conservative 5 req/s with delays: ~2 minutes total
- `withRetry()` in extractPage already handles 429 rate limit errors with exponential backoff
- Add configurable delay between requests as extra safety

### Output Structure

```
src/data/extracted/
  ai-governance.json          # depth 0, position 1
  ai-security.json            # depth 0, position 2
  ...
  regulatory-compliance-management--dora--implementation.json  # hierarchical slugs use -- separator
  ...
```

**File naming:** Use the page slug, replacing `/` with `--` to create flat filenames from hierarchical slugs. This preserves the hierarchy information while being filesystem-safe.

### Established Patterns

From `faq-batch-runner.ts` and `generate-queue.ts`:
- Dry-run default, `--execute` for actual operations (from Phase 3 Decision #13)
- Progress logging via `logger.progress(current, total, message)`
- JSON output with `--json` flag
- Import upstream functions with `import.meta.url` guard

## Tasks

### Task 1: Create batch extraction tool

Create `src/tools/extract-batch.ts` with:

1. **CLI Arguments**:
   - `--limit <N>` — process only first N pages from queue (default: all)
   - `--output-dir <path>` — output directory (default: `src/data/extracted`)
   - `--delay <ms>` — delay between API requests in ms (default: 200)
   - `--force` — re-extract pages even if output file already exists (default: skip existing)
   - `--queue <path>` — path to translation queue JSON (default: `src/data/translation-queue.json`)
   - `--json` — output summary as JSON to stdout

2. **Core logic**:
   - Read translation queue from JSON file
   - Apply `--limit` if specified
   - For each queue entry:
     a. Derive output filename from slug: replace `/` with `--`, append `.json`
     b. If output file exists and `--force` not set, skip (log as "already extracted")
     c. Call `extractPage(germanId)` from 05-01
     d. Write result to output directory
     e. Log progress: `[current/total] Extracted: <slug>`
     f. Wait `--delay` ms before next request
     g. On error: log error, continue to next page (don't abort batch)
   - At end: print summary (extracted, skipped, failed, total)

3. **Error handling**:
   - Catch errors per page, don't abort the entire batch
   - Track failed pages with their error messages
   - Report failures in the summary
   - If ALL pages fail (e.g., auth error), abort early after 5 consecutive failures

4. **Output**:
   - Create output directory if it doesn't exist
   - Add `src/data/extracted/.gitkeep` for empty directory tracking
   - Add `src/data/extracted/` to `.gitignore` (extracted data is regenerable, not committed)

5. **Add npm script**: `"extract-batch": "tsx src/tools/extract-batch.ts"`

### Task 2: Test batch extraction with small sample

Run the batch extractor on a limited sample:

1. **Test with limit 5:**
   ```bash
   npx tsx src/tools/extract-batch.ts --limit 5
   ```
   - Verify 5 JSON files created in `src/data/extracted/`
   - Verify filenames match slug convention
   - Verify each file contains valid ExtractedPage JSON
   - Verify progress logging shows [1/5] through [5/5]

2. **Test skip-existing:**
   - Run again with `--limit 5` (no --force)
   - Verify all 5 are "skipped" (already exist)
   - Verify output says "0 extracted, 5 skipped"

3. **Test force re-extract:**
   - Run with `--limit 2 --force`
   - Verify 2 files are re-extracted (not skipped)

4. **Clean up:** Remove test extracted files (keep .gitkeep)

## Verification

- [ ] `npx tsx src/tools/extract-batch.ts --limit 5` extracts 5 pages to `src/data/extracted/`
- [ ] Each output file is valid JSON with all ExtractedPage fields
- [ ] Filenames use slug with `/` → `--` replacement
- [ ] Skip-existing works (re-running skips already-extracted pages)
- [ ] `--force` overrides skip behavior
- [ ] Failed pages don't abort the batch
- [ ] Summary at end shows: extracted count, skipped count, failed count
- [ ] `--delay` controls inter-request timing
- [ ] `npm run extract-batch -- --limit 5` works via npm script

## Success Criteria

A batch extraction tool that:
1. Processes translation queue entries sequentially with rate limiting
2. Produces one clean JSON file per page in the output directory
3. Supports resume (skip-existing) for interrupted runs
4. Reports clear progress and summary statistics
5. Handles individual page failures gracefully without aborting

## Output

- `src/tools/extract-batch.ts` — batch extraction tool (~150-200 lines)
- `src/data/extracted/.gitkeep` — directory marker
- Updated `package.json` with `"extract-batch"` script
- Updated `.gitignore` with `src/data/extracted/*.json`
