import 'dotenv/config'
import { createClient } from '@sanity/client'

// Create client with direct credentials
const client = createClient({
  projectId: 'wwmm9rbb',
  dataset: 'production',
  apiVersion: '2024-02-14',
  token: process.env.SANITY_API_TOKEN,
  useCdn: false,
})

// Helper function to generate unique keys
function generateKey(prefix: string, index: number): string {
  return `${prefix}_${Date.now()}_${index}`
}

const run = async () => {
  try {
    console.log('Updating DORA Informationsregister page with FAQ batch 2...')
    
    // First, get the existing document
    console.log('Fetching existing document...')
    const existingDoc = await client.fetch('*[_id == $id][0]', { id: 'dora-informationsregister' })
    
    if (!existingDoc) {
      throw new Error('Document "dora-informationsregister" not found')
    }
    
    // Create new FAQs for DORA information register advanced topics
    const newFaqs = [
      {
        _type: 'object',
        _key: generateKey('faq', 5),
        question: 'Wie integriere ich mein DORA-Informationsregister mit bestehenden ITSM- und CMDB-Systemen?',
        answer: "Die Integration von DORA-Informationsregistern mit bestehenden IT Service Management und Configuration Management Database Systemen ist entscheidend f√ºr operative Effizienz und Datenqualit√§t. Eine nahtlose Integration eliminiert Datensilos, reduziert manuellen Aufwand und gew√§hrleistet konsistente Informationen √ºber alle IT-Governance-Prozesse hinweg.\n\nüîó CMDB-Integration und Datenharmonisierung:\n‚Ä¢ Mapping bestehender CMDB-Datenstrukturen auf DORA-spezifische Anforderungen und Erweiterung um fehlende Attribute\n‚Ä¢ Implementierung bidirektionaler Synchronisation zwischen CMDB und Informationsregister f√ºr konsistente Datenhaltung\n‚Ä¢ Entwicklung von Transformation-Rules f√ºr unterschiedliche Datenformate und Klassifizierungsschemata\n‚Ä¢ Etablierung von Master-Data-Management-Prinzipien zur Vermeidung von Duplikaten und Inkonsistenzen\n‚Ä¢ Integration von CMDB-Relationship-Modellen f√ºr umfassende Abh√§ngigkeitsanalysen\n\n‚öôÔ∏è ITSM-Workflow-Integration und Prozessautomatisierung:\n‚Ä¢ Automatische Aktualisierung des Informationsregisters bei Change-Requests und Incident-Management-Aktivit√§ten\n‚Ä¢ Integration von Service-Level-Management-Daten f√ºr Business-Impact-Bewertungen\n‚Ä¢ Workflow-basierte Genehmigungsprozesse f√ºr kritische Register-√Ñnderungen\n‚Ä¢ Automated-Ticket-Generation bei Compliance-Abweichungen oder Datenqualit√§tsproblemen\n‚Ä¢ Integration mit Problem-Management f√ºr Root-Cause-Analysen und kontinuierliche Verbesserung\n\nüìä API-basierte Integration und Real-Time-Synchronisation:\n‚Ä¢ RESTful-API-Entwicklung f√ºr standardisierte Datenintegration zwischen verschiedenen Systemen\n‚Ä¢ Event-driven Architecture f√ºr Real-Time-Updates bei kritischen System-√Ñnderungen\n‚Ä¢ Message-Queue-Integration f√ºr zuverl√§ssige Daten√ºbertragung und Fehlerbehandlung\n‚Ä¢ Webhook-basierte Benachrichtigungen f√ºr zeitkritische Informationsregister-Updates\n‚Ä¢ GraphQL-Integration f√ºr flexible und effiziente Datenabfragen\n\nüõ†Ô∏è Legacy-System-Integration und Modernisierung:\n‚Ä¢ ETL-Pipeline-Entwicklung f√ºr Datenextraktion aus Legacy-Systemen ohne native API-Unterst√ºtzung\n‚Ä¢ Database-Connector-Implementation f√ºr direkte Integration mit bestehenden Datenquellen\n‚Ä¢ File-based Integration f√ºr Systeme mit begrenzten Integrationsm√∂glichkeiten\n‚Ä¢ Graduelle Modernisierung bestehender Systeme zur Verbesserung der Integrationsf√§higkeiten\n‚Ä¢ Hybrid-Ans√§tze f√ºr schrittweise Migration zu modernen Integration-Architekturen\n\nüîç Monitoring und Governance der Integration:\n‚Ä¢ Comprehensive-Logging und Audit-Trails f√ºr alle Integrations-Aktivit√§ten\n‚Ä¢ Data-Quality-Monitoring f√ºr kontinuierliche √úberwachung der Integrations-Performance\n‚Ä¢ Exception-Handling und Alerting bei Integrations-Fehlern oder Dateninkonsistenzen\n‚Ä¢ Performance-Monitoring und Optimierung der Integrations-Workflows\n‚Ä¢ Compliance-Reporting f√ºr regulatorische Anforderungen bez√ºglich Datenintegrit√§t"
      },
      {
        _type: 'object',
        _key: generateKey('faq', 6),
        question: 'Welche Herausforderungen gibt es bei der F√ºhrung von Informationsregistern in hybriden und Multi-Cloud-Umgebungen?',
        answer: "Die F√ºhrung von DORA-Informationsregistern in hybriden und Multi-Cloud-Umgebungen bringt einzigartige Komplexit√§ten mit sich, die traditionelle On-Premises-Ans√§tze √ºbersteigen. Die dynamische Natur von Cloud-Services, unterschiedliche Provider-APIs und verteilte Governance-Modelle erfordern spezialisierte Strategien f√ºr vollst√§ndige Transparenz und Compliance.\n\n‚òÅÔ∏è Cloud-Provider-spezifische Herausforderungen:\n‚Ä¢ Unterschiedliche API-Standards und Datenformate zwischen verschiedenen Cloud-Providern erfordern individuelle Integrations-Ans√§tze\n‚Ä¢ Dynamische Ressourcen-Allokation und Auto-Scaling f√ºhren zu kontinuierlichen √Ñnderungen in der IKT-Landschaft\n‚Ä¢ Provider-spezifische Service-Kategorisierungen und Naming-Conventions erschweren einheitliche Klassifizierung\n‚Ä¢ Verschiedene Sicherheits- und Compliance-Standards zwischen Providern erfordern differenzierte Bewertungsans√§tze\n‚Ä¢ Vendor-Lock-in-Risiken und begrenzte Portabilit√§t von Konfigurationsdaten zwischen Plattformen\n\nüåê Governance und Compliance in verteilten Umgebungen:\n‚Ä¢ Jurisdiktionale Komplexit√§ten durch geografisch verteilte Cloud-Services und unterschiedliche Datenschutzbestimmungen\n‚Ä¢ Herausforderungen bei der einheitlichen Anwendung von Governance-Policies √ºber verschiedene Cloud-Umgebungen hinweg\n‚Ä¢ Schwierigkeiten bei der Nachverfolgung von Datenfl√ºssen und -speicherorten in Multi-Cloud-Architekturen\n‚Ä¢ Komplexe Verantwortlichkeits-Zuordnungen zwischen internen Teams und verschiedenen Cloud-Providern\n‚Ä¢ Herausforderungen bei der Auditierbarkeit und Nachweisf√ºhrung f√ºr regulatorische Anforderungen\n\nüîÑ Dynamische Ressourcen-Verwaltung und Lifecycle-Management:\n‚Ä¢ Ephemere Ressourcen und Container-basierte Services erschweren traditionelle Asset-Tracking-Ans√§tze\n‚Ä¢ Infrastructure-as-Code-Deployments f√ºhren zu schnellen und h√§ufigen Konfigurations√§nderungen\n‚Ä¢ Serverless-Computing und Function-as-a-Service-Modelle erfordern neue Kategorisierungs- und Bewertungsans√§tze\n‚Ä¢ Auto-Scaling und Load-Balancing f√ºhren zu variablen Ressourcen-Konfigurationen\n‚Ä¢ DevOps-Praktiken und Continuous-Deployment-Pipelines erh√∂hen die √Ñnderungsfrequenz erheblich\n\nüõ°Ô∏è Sicherheit und Risikomanagement in hybriden Umgebungen:\n‚Ä¢ Komplexe Netzwerk-Topologien mit VPNs, Private-Links und Hybrid-Connectivity erschweren Abh√§ngigkeits-Mapping\n‚Ä¢ Unterschiedliche Sicherheits-Postures zwischen On-Premises und verschiedenen Cloud-Umgebungen\n‚Ä¢ Herausforderungen bei der einheitlichen Identit√§ts- und Zugriffsverwaltung √ºber verschiedene Plattformen hinweg\n‚Ä¢ Schwierigkeiten bei der Korrelation von Sicherheitsereignissen √ºber verteilte Infrastrukturen\n‚Ä¢ Komplexe Backup- und Disaster-Recovery-Szenarien mit verschiedenen Recovery-Strategien pro Umgebung\n\nüìà Technologische L√∂sungsans√§tze und Best Practices:\n‚Ä¢ Cloud-Management-Plattformen f√ºr einheitliche Sicht auf Multi-Cloud-Ressourcen\n‚Ä¢ Infrastructure-Discovery-Tools mit Cloud-nativen Integrations-Capabilities\n‚Ä¢ Policy-as-Code-Ans√§tze f√ºr konsistente Governance √ºber verschiedene Umgebungen hinweg\n‚Ä¢ Cloud-Security-Posture-Management-Tools f√ºr kontinuierliche Compliance-√úberwachung\n‚Ä¢ Federated-Identity-Management f√ºr einheitliche Zugriffskontrolle und Audit-Trails"
      },
      {
        _type: 'object',
        _key: generateKey('faq', 7),
        question: 'Wie entwickle ich effektive Metriken und KPIs zur Messung der Qualit√§t und Vollst√§ndigkeit meines DORA-Informationsregisters?',
        answer: "Die Entwicklung aussagekr√§ftiger Metriken und KPIs f√ºr DORA-Informationsregister ist entscheidend f√ºr kontinuierliche Verbesserung und Compliance-Nachweis. Effektive Metriken m√ºssen sowohl quantitative Aspekte der Datenqualit√§t als auch qualitative Dimensionen der Nutzbarkeit und Gesch√§ftsrelevanz erfassen, um ein vollst√§ndiges Bild der Register-Performance zu liefern.\n\nüìä Datenqualit√§ts-Metriken und Vollst√§ndigkeits-Indikatoren:\n‚Ä¢ Completeness-Rate f√ºr kritische Datenfelder mit gewichteter Bewertung basierend auf Gesch√§ftskritikalit√§t\n‚Ä¢ Data-Freshness-Metriken zur Messung der Aktualit√§t von Informationen mit differenzierten Schwellenwerten f√ºr verschiedene Asset-Kategorien\n‚Ä¢ Accuracy-Scores durch automatisierte Validierung gegen authoritative Datenquellen\n‚Ä¢ Consistency-Metriken f√ºr Datenharmonisierung zwischen verschiedenen Systemen und Datenquellen\n‚Ä¢ Duplicate-Detection-Rates und Data-Deduplication-Effektivit√§t\n\nüéØ Compliance und Governance-KPIs:\n‚Ä¢ DORA-Readiness-Score basierend auf Vollst√§ndigkeit regulatorisch relevanter Informationen\n‚Ä¢ Audit-Trail-Completeness f√ºr Nachverfolgbarkeit aller Daten√§nderungen\n‚Ä¢ Policy-Compliance-Rate f√ºr Einhaltung interner Datengovernance-Standards\n‚Ä¢ Regulatory-Reporting-Readiness-Metriken f√ºr zeitnahe Bereitstellung aufsichtsrechtlicher Informationen\n‚Ä¢ Risk-Coverage-Ratio zur Bewertung der Abdeckung aller identifizierten IKT-Risiken\n\n‚ö° Operational-Excellence und Performance-Indikatoren:\n‚Ä¢ Mean-Time-to-Update f√ºr kritische Asset-√Ñnderungen\n‚Ä¢ User-Adoption-Rates und System-Utilization-Metriken\n‚Ä¢ Query-Response-Times und System-Performance-Benchmarks\n‚Ä¢ Incident-Response-Effectiveness basierend auf Register-Informationen\n‚Ä¢ Change-Management-Efficiency durch automatisierte Register-Updates\n\nüîç Business-Value und Impact-Metriken:\n‚Ä¢ Risk-Mitigation-Effectiveness durch verbesserte Asset-Transparenz\n‚Ä¢ Cost-Avoidance durch proaktive Asset-Management-Ma√ünahmen\n‚Ä¢ Decision-Making-Speed-Improvement durch bessere Informationsverf√ºgbarkeit\n‚Ä¢ Stakeholder-Satisfaction-Scores f√ºr Register-Nutzer\n‚Ä¢ Business-Continuity-Preparedness basierend auf Register-Informationen\n\nüìà Kontinuierliche Verbesserung und Trend-Analyse:\n‚Ä¢ Data-Quality-Trend-Analysen f√ºr Identifikation systematischer Verbesserungsm√∂glichkeiten\n‚Ä¢ Predictive-Analytics f√ºr proaktive Identifikation potenzieller Datenqualit√§tsprobleme\n‚Ä¢ Benchmark-Vergleiche mit Industry-Standards und Best-Practices\n‚Ä¢ ROI-Metriken f√ºr Investitionen in Register-Verbesserungen\n‚Ä¢ Maturity-Assessment-Scores f√ºr kontinuierliche Capability-Entwicklung"
      },
      {
        _type: 'object',
        _key: generateKey('faq', 8),
        question: 'Welche Rolle spielen k√ºnstliche Intelligenz und Machine Learning bei der Optimierung von DORA-Informationsregistern?',
        answer: "K√ºnstliche Intelligenz und Machine Learning revolutionieren die Verwaltung von DORA-Informationsregistern durch Automatisierung komplexer Aufgaben, proaktive Anomalie-Erkennung und intelligente Datenanalyse. Diese Technologien erm√∂glichen es, die Qualit√§t, Vollst√§ndigkeit und Nutzbarkeit von Informationsregistern erheblich zu verbessern und gleichzeitig den manuellen Aufwand zu reduzieren.\n\nü§ñ Intelligente Datenklassifizierung und Asset-Kategorisierung:\n‚Ä¢ Natural Language Processing f√ºr automatische Klassifizierung von Asset-Beschreibungen und Dokumentationen\n‚Ä¢ Computer Vision f√ºr automatische Erkennung und Kategorisierung von Netzwerk-Diagrammen und Infrastruktur-Dokumentationen\n‚Ä¢ Supervised Learning f√ºr kontinuierliche Verbesserung der Klassifizierungsgenauigkeit basierend auf Experten-Feedback\n‚Ä¢ Unsupervised Learning f√ºr Entdeckung neuer Asset-Kategorien und Muster in der IKT-Landschaft\n‚Ä¢ Transfer Learning f√ºr Anwendung bew√§hrter Klassifizierungsmodelle auf neue Umgebungen\n\nüîç Proaktive Anomalie-Erkennung und Qualit√§tssicherung:\n‚Ä¢ Anomaly Detection f√ºr Identifikation ungew√∂hnlicher Konfigurations√§nderungen oder Dateninkonsistenzen\n‚Ä¢ Predictive Analytics f√ºr Vorhersage potenzieller Asset-Ausf√§lle oder Wartungsbedarfe\n‚Ä¢ Pattern Recognition f√ºr Identifikation wiederkehrender Datenqualit√§tsprobleme\n‚Ä¢ Outlier Detection f√ºr Identifikation von Assets mit ungew√∂hnlichen Eigenschaften oder Risikoprofilen\n‚Ä¢ Time Series Analysis f√ºr Trend-Erkennung in Asset-Performance und Nutzungsmustern\n\nüìä Intelligente Datenintegration und Harmonisierung:\n‚Ä¢ Entity Resolution f√ºr automatische Identifikation und Verkn√ºpfung verwandter Assets √ºber verschiedene Datenquellen hinweg\n‚Ä¢ Schema Matching f√ºr automatische Zuordnung von Datenfeldern zwischen verschiedenen Systemen\n‚Ä¢ Data Fusion f√ºr intelligente Kombination von Informationen aus mehreren Quellen\n‚Ä¢ Conflict Resolution f√ºr automatische Aufl√∂sung widerspr√ºchlicher Informationen\n‚Ä¢ Semantic Analysis f√ºr besseres Verst√§ndnis von Datenbeziehungen und Kontexten\n\nüéØ Risikobewertung und Impact-Analyse:\n‚Ä¢ Risk Scoring Models f√ºr automatische Bewertung von Asset-Risiken basierend auf historischen Daten und Umgebungsfaktoren\n‚Ä¢ Dependency Analysis f√ºr intelligente Identifikation kritischer Pfade und Single Points of Failure\n‚Ä¢ Impact Simulation f√ºr Vorhersage der Auswirkungen potenzieller Asset-Ausf√§lle\n‚Ä¢ Vulnerability Assessment f√ºr automatische Bewertung von Sicherheitsrisiken\n‚Ä¢ Business Impact Modeling f√ºr quantitative Bewertung der Gesch√§ftsauswirkungen\n\nüöÄ Automatisierung und Workflow-Optimierung:\n‚Ä¢ Intelligent Process Automation f√ºr automatisierte Datensammlung und Validierung\n‚Ä¢ Chatbot-Integration f√ºr nat√ºrlichsprachliche Abfragen des Informationsregisters\n‚Ä¢ Automated Report Generation f√ºr intelligente Erstellung regulatorischer Berichte\n‚Ä¢ Smart Alerting f√ºr kontextuelle Benachrichtigungen basierend auf Benutzerverhalten und Priorit√§ten\n‚Ä¢ Recommendation Engines f√ºr Vorschl√§ge zur Verbesserung der Register-Qualit√§t und Compliance"
      }
    ]
    
    // Update the document with new FAQs
    const updatedFaqs = [...(existingDoc.faq || []), ...newFaqs]
    
    console.log(`Adding ${newFaqs.length} new FAQs to the document...`)
    const transaction = client.transaction()
    transaction.patch(existingDoc._id, {
      set: {
        faq: updatedFaqs
      }
    })
    
    await transaction.commit()
    console.log('‚úÖ FAQ batch 2 added successfully')
  } catch (error) {
    console.error('Error:', error)
    throw error
  }
}

run()
