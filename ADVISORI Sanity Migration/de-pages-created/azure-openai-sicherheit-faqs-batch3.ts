import 'dotenv/config'
import { createClient } from '@sanity/client'

// Create client with direct credentials
const client = createClient({
  projectId: 'wwmm9rbb',
  dataset: 'production',
  apiVersion: '2024-02-14',
  token: process.env.SANITY_API_TOKEN,
  useCdn: false,
})

// Helper function to generate unique keys
function generateKey(prefix: string, index: number): string {
  return `${prefix}_${Date.now()}_${index}`
}

const run = async () => {
  try {
    console.log('Updating Azure OpenAI Sicherheit page with FAQs batch 3...')
    
    // First, get the existing document
    console.log('Fetching existing document...')
    const existingDoc = await client.fetch('*[_id == $id][0]', { id: 'azure-openai-sicherheit' })
    
    if (!existingDoc) {
      throw new Error('Document "azure-openai-sicherheit" not found')
    }
    
    // Create new FAQs focusing on enterprise governance and risk management
    const newFaqs = [
      {
        _type: 'object',
        _key: generateKey('faq', 9),
        question: "Wie entwickelt ADVISORI eine umfassende Azure OpenAI Governance-Strategie f√ºr Gro√üunternehmen und welche Rolle spielen Board-Level-Entscheidungen bei der AI-Sicherheitsstrategie?",
        answer: "Enterprise-Governance f√ºr Azure OpenAI erfordert eine strategische Herangehensweise, die technische Exzellenz mit Board-Level-Verantwortung verbindet. ADVISORI entwickelt mehrstufige Governance-Frameworks, die von der strategischen Ebene bis zur operativen Umsetzung reichen und dabei alle Stakeholder-Interessen ber√ºcksichtigen. Unser Ansatz schafft Transparenz, Verantwortlichkeit und strategische Ausrichtung.\n\nüèõÔ∏è Board-Level-Governance-Dimensionen:\n‚Ä¢ Strategische AI-Oversight: Etablierung von Board-Komitees oder -Funktionen, die speziell f√ºr AI-Governance und -Risikomanagement verantwortlich sind und regelm√§√üige Berichte √ºber AI-Sicherheit und -Performance erhalten.\n‚Ä¢ Risk-Appetite-Definition: Klare Definition des Risikoappetits f√ºr AI-Initiativen auf Vorstandsebene, einschlie√ülich Toleranzschwellen f√ºr verschiedene Risikokategorien.\n‚Ä¢ Compliance-Accountability: Etablierung klarer Verantwortlichkeiten und Rechenschaftspflichten f√ºr AI-Compliance auf allen Unternehmensebenen.\n‚Ä¢ Strategic-Alignment-Mechanisms: Sicherstellung, dass AI-Sicherheitsstrategien mit √ºbergeordneten Unternehmenszielen und -werten harmonieren.\n\nüîÑ ADVISORI's Multi-Tier-Governance-Framework:\n‚Ä¢ Executive-Steering-Committees: Einrichtung von Lenkungsaussch√ºssen mit C-Level-Beteiligung f√ºr strategische AI-Entscheidungen und Ressourcenallokation.\n‚Ä¢ Operational-Governance-Bodies: Etablierung operativer Governance-Gremien, die t√§gliche AI-Sicherheitsentscheidungen treffen und Eskalationswege f√ºr kritische Issues definieren.\n‚Ä¢ Cross-Functional-Integration: Integration von AI-Governance in bestehende Unternehmensstrukturen wie Risikomanagement, Compliance und IT-Governance.\n‚Ä¢ Stakeholder-Communication-Strategies: Entwicklung von Kommunikationsstrategien, die verschiedene Stakeholder-Gruppen √ºber AI-Sicherheitsma√ünahmen und -Performance informieren."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 10),
        question: "Welche spezifischen Risikomanagement-Frameworks implementiert ADVISORI f√ºr Azure OpenAI und wie werden diese in bestehende Enterprise-Risk-Management-Systeme integriert?",
        answer: "Effektives Risikomanagement f√ºr Azure OpenAI erfordert spezialisierte Frameworks, die die einzigartigen Herausforderungen von Cloud-AI adressieren und gleichzeitig nahtlos in bestehende Enterprise-Risk-Management-Systeme integriert werden. ADVISORI entwickelt ma√ügeschneiderte Risikomanagement-Ans√§tze, die proaktive Identifikation, Bewertung und Mitigation von AI-spezifischen Risiken erm√∂glichen.\n\n‚öñÔ∏è AI-spezifische Risikokategorien und -bewertung:\n‚Ä¢ Technical-Risk-Assessment: Systematische Bewertung technischer Risiken wie Model-Drift, Performance-Degradation, Adversarial-Attacks und System-Failures mit quantitativen Risikometriken.\n‚Ä¢ Operational-Risk-Integration: Integration von AI-Risiken in bestehende Operational-Risk-Frameworks, einschlie√ülich Prozessrisiken, Human-Error-Faktoren und Change-Management-Herausforderungen.\n‚Ä¢ Regulatory-and-Compliance-Risk-Monitoring: Kontinuierliche √úberwachung sich entwickelnder regulatorischer Landschaften und deren Auswirkungen auf AI-Implementierungen.\n‚Ä¢ Reputational-and-Strategic-Risk-Considerations: Bewertung von Reputationsrisiken durch AI-Failures oder -Bias sowie strategischen Risiken durch verpasste AI-Innovationschancen.\n\nüõ°Ô∏è ADVISORI's Integrated-Risk-Management-Approach:\n‚Ä¢ Risk-Register-Integration: Entwicklung spezialisierter AI-Risk-Register, die nahtlos in bestehende Enterprise-Risk-Management-Systeme integriert werden und einheitliche Risikobewertung erm√∂glichen.\n‚Ä¢ Automated-Risk-Monitoring: Implementierung automatisierter Systeme zur kontinuierlichen √úberwachung von AI-Performance-Metriken und fr√ºhzeitigen Erkennung von Risikoindikatoren.\n‚Ä¢ Scenario-Planning-and-Stress-Testing: Entwicklung von Szenario-Analysen und Stress-Tests, die die Widerstandsf√§higkeit von AI-Systemen unter verschiedenen Bedingungen bewerten.\n‚Ä¢ Risk-Mitigation-Playbooks: Erstellung detaillierter Handlungsanleitungen f√ºr verschiedene Risikoszenarien, einschlie√ülich Eskalationsprozessen und Notfallma√ünahmen."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 11),
        question: "Wie stellt ADVISORI sicher, dass Azure OpenAI Implementierungen den internen Audit-Anforderungen und externen Pr√ºfungsstandards entsprechen und welche Dokumentations- und Nachweispflichten entstehen?",
        answer: "Audit-Readiness f√ºr Azure OpenAI erfordert umfassende Dokumentation, nachvollziehbare Prozesse und kontinuierliche Compliance-√úberwachung. ADVISORI entwickelt audit-sichere Implementierungen, die nicht nur aktuellen Pr√ºfungsstandards entsprechen, sondern auch f√ºr zuk√ºnftige Audit-Anforderungen ger√ºstet sind. Unser Ansatz schafft Transparenz und Vertrauen bei internen und externen Pr√ºfern.\n\nüìã Audit-spezifische Dokumentationsanforderungen:\n‚Ä¢ Comprehensive-System-Documentation: Erstellung detaillierter Dokumentationen √ºber AI-Systemarchitekturen, Datenfl√ºsse, Entscheidungslogiken und Sicherheitskontrollen f√ºr vollst√§ndige Audit-Transparenz.\n‚Ä¢ Process-and-Procedure-Evidence: Dokumentation aller AI-bezogenen Prozesse und Verfahren, einschlie√ülich Change-Management, Incident-Response und Compliance-√úberwachung.\n‚Ä¢ Control-Effectiveness-Testing: Implementierung von Mechanismen zur regelm√§√üigen √úberpr√ºfung der Wirksamkeit von Sicherheitskontrollen und Compliance-Ma√ünahmen.\n‚Ä¢ Audit-Trail-Completeness: Sicherstellung l√ºckenloser Audit-Trails f√ºr alle AI-Aktivit√§ten, von Datenverarbeitung bis zu System√§nderungen.\n\nüîç ADVISORI's Audit-Excellence-Framework:\n‚Ä¢ Continuous-Audit-Readiness: Implementierung von Systemen, die kontinuierliche Audit-Bereitschaft gew√§hrleisten und Ad-hoc-Pr√ºfungen ohne umfangreiche Vorbereitungszeit erm√∂glichen.\n‚Ä¢ Automated-Evidence-Collection: Deployment automatisierter Systeme zur Sammlung und Aufbereitung von Audit-Evidenzen, die menschliche Fehler minimieren und Effizienz steigern.\n‚Ä¢ Multi-Framework-Compliance: Design von Compliance-Strukturen, die gleichzeitig verschiedene Audit-Standards und -Frameworks erf√ºllen, von SOC bis zu branchenspezifischen Anforderungen.\n‚Ä¢ Auditor-Collaboration-Strategies: Entwicklung von Strategien f√ºr effektive Zusammenarbeit mit internen und externen Auditoren, einschlie√ülich Schulungen und Kommunikationspl√§nen."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 12),
        question: "Welche Rolle spielt Change Management bei Azure OpenAI Sicherheit und wie gew√§hrleistet ADVISORI, dass Sicherheitsstandards auch bei kontinuierlichen System-Updates und -Erweiterungen erhalten bleiben?",
        answer: "Change Management ist ein kritischer Erfolgsfaktor f√ºr nachhaltige Azure OpenAI Sicherheit, da AI-Systeme kontinuierlichen Updates, Modell-Refreshes und Funktionserweiterungen unterliegen. ADVISORI entwickelt robuste Change-Management-Frameworks, die Innovation erm√∂glichen, ohne dabei Sicherheit oder Compliance zu gef√§hrden. Unser Ansatz balanciert Agilit√§t mit Kontrolle.\n\nüîÑ Change-Management-Herausforderungen bei Cloud-AI:\n‚Ä¢ Model-Update-Governance: Verwaltung von AI-Modell-Updates, die sowohl Performance-Verbesserungen als auch potenzielle Sicherheitsrisiken mit sich bringen k√∂nnen.\n‚Ä¢ Configuration-Change-Control: Kontrolle √ºber Konfigurations√§nderungen in komplexen Azure-Umgebungen, die multiple Services und Abh√§ngigkeiten umfassen.\n‚Ä¢ Third-Party-Integration-Management: Management von √Ñnderungen bei Integration mit Drittanbieter-Services oder -APIs, die Sicherheitsauswirkungen haben k√∂nnen.\n‚Ä¢ Emergency-Change-Procedures: Etablierung von Notfall-Change-Prozessen f√ºr kritische Sicherheits-Patches oder Incident-Response-Ma√ünahmen.\n\n‚öôÔ∏è ADVISORI's Secure-Change-Management-Excellence:\n‚Ä¢ Risk-Based-Change-Classification: Implementierung von Klassifizierungssystemen, die √Ñnderungen basierend auf Sicherheitsrisiken und Gesch√§ftsauswirkungen kategorisieren und entsprechende Genehmigungsprozesse definieren.\n‚Ä¢ Automated-Testing-and-Validation: Deployment automatisierter Test-Pipelines, die Sicherheits- und Compliance-Validierung in jeden Change-Prozess integrieren.\n‚Ä¢ Rollback-and-Recovery-Strategies: Entwicklung umfassender Rollback-Strategien und Recovery-Pl√§ne f√ºr den Fall, dass √Ñnderungen unerwartete Sicherheitsprobleme verursachen.\n‚Ä¢ Stakeholder-Communication-and-Approval: Etablierung klarer Kommunikations- und Genehmigungsprozesse, die alle relevanten Stakeholder in kritische √Ñnderungsentscheidungen einbeziehen."
      }
    ]
    
    // Update the document with new FAQs
    const updatedFaqs = [...(existingDoc.faq || []), ...newFaqs]
    
    console.log(`Adding ${newFaqs.length} new FAQs to the document...`)
    const transaction = client.transaction()
    transaction.patch(existingDoc._id, {
      set: {
        faq: updatedFaqs
      }
    })
    
    await transaction.commit()
    console.log('‚úÖ Azure OpenAI Sicherheit FAQs batch 3 added successfully')
  } catch (error) {
    console.error('Error:', error)
    throw error
  }
}

run()
