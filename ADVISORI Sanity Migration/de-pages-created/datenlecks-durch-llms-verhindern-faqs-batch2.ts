import 'dotenv/config'
import { createClient } from '@sanity/client'

// Create client with direct credentials
const client = createClient({
  projectId: 'wwmm9rbb',
  dataset: 'production',
  apiVersion: '2024-02-14',
  token: process.env.SANITY_API_TOKEN,
  useCdn: false,
})

// Helper function to generate unique keys
function generateKey(prefix: string, index: number): string {
  return `${prefix}_${Date.now()}_${index}`
}

const run = async () => {
  try {
    console.log('Updating Datenlecks durch LLMs verhindern page with Technical Implementation FAQs batch 2 (German)...')
    
    // First, get the existing document
    console.log('Fetching existing document...')
    const existingDoc = await client.fetch('*[_id == $id][0]', { id: 'datenlecks-durch-llms-verhindern' })
    
    if (!existingDoc) {
      throw new Error('Document "datenlecks-durch-llms-verhindern" not found')
    }
    
    // Create new Technical Implementation FAQs in German
    const newFaqs = [
      {
        _type: 'object',
        _key: generateKey('faq', 5),
        question: "Wie implementiert ADVISORI technische Schutzma√ünahmen gegen Prompt Injection und Data Exfiltration in LLM-Systemen?",
        answer: "Prompt Injection und Data Exfiltration geh√∂ren zu den kritischsten Sicherheitsbedrohungen f√ºr LLM-Systeme. ADVISORI entwickelt mehrschichtige technische Schutzma√ünahmen, die diese Angriffsvektoren proaktiv erkennen, blockieren und dokumentieren. Unser Ansatz kombiniert pr√§ventive Sicherheitsarchitekturen mit intelligenter Anomalie-Erkennung f√ºr umfassenden Schutz.\n\nüõ°Ô∏è Prompt Injection Prevention Technologien:\n‚Ä¢ Input-Sanitization und Validierung: Implementierung robuster Input-Filter, die sch√§dliche Prompts erkennen und neutralisieren, bevor sie das LLM erreichen, ohne die Funktionalit√§t zu beeintr√§chtigen.\n‚Ä¢ Prompt-Template-Systeme: Entwicklung sicherer Prompt-Templates mit definierten Parametern, die unautorisierten Code oder Befehle verhindern und gleichzeitig Flexibilit√§t gew√§hrleisten.\n‚Ä¢ Context-Isolation-Techniken: Implementierung von Kontext-Isolation, die verhindert, dass Benutzer-Inputs die System-Prompts oder andere Benutzer-Sessions beeinflussen k√∂nnen.\n‚Ä¢ Semantic Analysis Engines: Einsatz fortschrittlicher semantischer Analysesysteme, die verd√§chtige Prompt-Muster und Manipulationsversuche in Echtzeit identifizieren.\n\nüîí Data Exfiltration Prevention Systeme:\n‚Ä¢ Output-Filtering und Content-Kontrolle: Implementierung intelligenter Output-Filter, die sensible Daten in LLM-Antworten erkennen und redaktieren, bevor sie an Benutzer √ºbertragen werden.\n‚Ä¢ Data Loss Prevention Integration: Nahtlose Integration spezialisierter DLP-Systeme, die f√ºr LLM-Umgebungen optimiert sind und verschiedene Datentypen und -klassifikationen √ºberwachen.\n‚Ä¢ Real-time Monitoring und Alerting: Kontinuierliche √úberwachung aller LLM-Interaktionen mit sofortigen Benachrichtigungen bei verd√§chtigen Aktivit√§ten oder Anomalien.\n‚Ä¢ Forensische Logging und Audit-Trails: Umfassende Protokollierung aller Sicherheitsereignisse f√ºr forensische Analyse und Compliance-Nachweis."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 6),
        question: "Welche Architekturprinzipien wendet ADVISORI f√ºr sichere LLM-Implementierungen an und wie gew√§hrleisten diese Privacy-by-Design?",
        answer: "ADVISORI folgt strengen Architekturprinzipien, die Sicherheit und Datenschutz von Grund auf in LLM-Systeme integrieren. Unser Privacy-by-Design-Ansatz gew√§hrleistet, dass Datenschutz nicht nachtr√§glich hinzugef√ºgt, sondern als fundamentales Designprinzip implementiert wird. Diese Architektur schafft vertrauensvolle LLM-Umgebungen ohne Kompromisse bei der Funktionalit√§t.\n\nüèóÔ∏è Sichere LLM-Architekturprinzipien:\n‚Ä¢ Zero-Trust-Architektur: Implementierung von Zero-Trust-Prinzipien, bei denen jede Anfrage, jeder Benutzer und jedes System kontinuierlich verifiziert wird, unabh√§ngig von der Netzwerkposition.\n‚Ä¢ Mikroservice-basierte Isolation: Aufbau modularer LLM-Systeme mit isolierten Mikroservices, die Sicherheitsverletzungen eind√§mmen und granulare Sicherheitskontrollen erm√∂glichen.\n‚Ä¢ End-to-End-Verschl√ºsselung: Implementierung umfassender Verschl√ºsselung f√ºr Daten in Ruhe, in Bewegung und in Verarbeitung, um sensible Informationen durchg√§ngig zu sch√ºtzen.\n‚Ä¢ Secure Enclaves und Containerisierung: Einsatz sicherer Container-Technologien und Hardware-basierter Enclaves f√ºr zus√§tzliche Isolation kritischer LLM-Komponenten.\n\nüîê Privacy-by-Design-Implementierung:\n‚Ä¢ Datenminimierung und Zweckbindung: Architektur-Design, das nur notwendige Daten verarbeitet und strenge Zweckbindung f√ºr alle Datenverarbeitungsprozesse gew√§hrleistet.\n‚Ä¢ Anonymisierung und Pseudonymisierung: Integration fortschrittlicher Anonymisierungstechniken, die personenbezogene Daten sch√ºtzen, ohne die LLM-Funktionalit√§t zu beeintr√§chtigen.\n‚Ä¢ Granulare Zugriffskontrolle: Implementierung feingranularer Berechtigungssysteme mit rollenbasiertem Zugriff und dynamischen Sicherheitsrichtlinien.\n‚Ä¢ Transparenz und Auditierbarkeit: Architektur-Design, das vollst√§ndige Transparenz und Nachvollziehbarkeit aller Datenverarbeitungsprozesse gew√§hrleistet."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 7),
        question: "Wie gew√§hrleistet ADVISORI die sichere Integration von LLMs in bestehende Unternehmensinfrastrukturen ohne Sicherheitsl√ºcken?",
        answer: "Die sichere Integration von LLMs in bestehende Unternehmensinfrastrukturen erfordert einen systematischen Ansatz, der sowohl neue als auch legacy Systeme ber√ºcksichtigt. ADVISORI entwickelt ma√ügeschneiderte Integrationsl√∂sungen, die Sicherheit, Kompatibilit√§t und Performance optimieren, w√§hrend sie nahtlos in Ihre bestehende IT-Landschaft eingebettet werden.\n\nüîó Sichere Integrationsmethoden:\n‚Ä¢ API-Gateway-Sicherheit: Implementierung sicherer API-Gateways mit umfassender Authentifizierung, Autorisierung und Rate-Limiting f√ºr alle LLM-Interaktionen mit bestehenden Systemen.\n‚Ä¢ Network Segmentation und Firewalling: Strategische Netzwerksegmentierung, die LLM-Systeme isoliert und gleichzeitig kontrollierte Kommunikation mit notwendigen Unternehmenssystemen erm√∂glicht.\n‚Ä¢ Identity und Access Management Integration: Nahtlose Integration in bestehende IAM-Systeme mit Single Sign-On, Multi-Faktor-Authentifizierung und zentralisierter Benutzerverwaltung.\n‚Ä¢ Legacy-System-Kompatibilit√§t: Entwicklung sicherer Adapter und Middleware-L√∂sungen, die moderne LLM-Sicherheit mit √§lteren Unternehmenssystemen verbinden.\n\n‚öôÔ∏è Infrastruktur-Sicherheitsma√ünahmen:\n‚Ä¢ Hybrid-Cloud-Sicherheit: Implementierung sicherer Hybrid-Cloud-Architekturen, die On-Premises-Sicherheitsanforderungen mit Cloud-basierter LLM-Flexibilit√§t kombinieren.\n‚Ä¢ Continuous Security Monitoring: Integration in bestehende SIEM-Systeme und Security Operations Centers f√ºr einheitliche Sicherheits√ºberwachung und Incident Response.\n‚Ä¢ Backup und Disaster Recovery: Entwicklung umfassender Backup- und Wiederherstellungsstrategien, die LLM-spezifische Anforderungen ber√ºcksichtigen.\n‚Ä¢ Performance und Skalierbarkeit: Architektur-Design, das sichere LLM-Integration ohne Beeintr√§chtigung der bestehenden Systemperformance gew√§hrleistet."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 8),
        question: "Welche spezialisierten Monitoring- und Anomalie-Erkennungssysteme setzt ADVISORI f√ºr LLM-Sicherheit ein?",
        answer: "ADVISORI implementiert fortschrittliche Monitoring- und Anomalie-Erkennungssysteme, die speziell f√ºr die einzigartigen Sicherheitsherausforderungen von LLM-Umgebungen entwickelt wurden. Diese Systeme kombinieren traditionelle Sicherheits√ºberwachung mit AI-spezifischen Bedrohungserkennung f√ºr umfassenden Schutz und proaktive Sicherheitsma√ünahmen.\n\nüìä Spezialisierte LLM-Monitoring-Systeme:\n‚Ä¢ Behavioral Analytics f√ºr LLMs: Implementierung fortschrittlicher Verhaltensanalyse-Systeme, die normale LLM-Interaktionsmuster lernen und Abweichungen identifizieren, die auf Sicherheitsbedrohungen hinweisen k√∂nnten.\n‚Ä¢ Real-time Prompt Analysis: Kontinuierliche Analyse aller eingehenden Prompts auf verd√§chtige Muster, Injection-Versuche oder ungew√∂hnliche Anfragevolumen mit sofortiger Alarmierung.\n‚Ä¢ Output Content Monitoring: Intelligente √úberwachung aller LLM-Outputs auf sensible Daten, ungew√∂hnliche Inhalte oder Anzeichen von Data Exfiltration mit automatischer Redaktion.\n‚Ä¢ Performance und Ressourcen-Monitoring: √úberwachung von LLM-Performance-Metriken zur Erkennung von DDoS-Angriffen, Ressourcenmissbrauch oder anderen Performance-basierten Bedrohungen.\n\nüö® Anomalie-Erkennungs-Technologien:\n‚Ä¢ Machine Learning-basierte Bedrohungserkennung: Einsatz spezialisierter ML-Modelle, die aus historischen LLM-Interaktionen lernen und neue Bedrohungsmuster automatisch identifizieren.\n‚Ä¢ Statistische Anomalie-Analyse: Implementierung statistischer Analysemethoden zur Erkennung ungew√∂hnlicher Nutzungsmuster, Anfragevolumen oder Interaktionssequenzen.\n‚Ä¢ Threat Intelligence Integration: Integration externer Threat Intelligence Feeds mit LLM-spezifischen Bedrohungsinformationen f√ºr proaktive Erkennung bekannter Angriffsmuster.\n‚Ä¢ Automated Incident Response: Entwicklung automatisierter Response-Systeme, die bei erkannten Anomalien sofortige Schutzma√ünahmen einleiten und Sicherheitsteams benachrichtigen."
      }
    ]
    
    // Update the document with new FAQs
    const updatedFaqs = [...(existingDoc.faq || []), ...newFaqs]
    
    console.log(`Adding ${newFaqs.length} new Technical Implementation FAQs (German) to the document...`)
    const transaction = client.transaction()
    transaction.patch(existingDoc._id, {
      set: {
        faq: updatedFaqs
      }
    })
    
    await transaction.commit()
    console.log('‚úÖ Technical Implementation FAQs batch 2 (German) added successfully')
  } catch (error) {
    console.error('Error:', error)
    throw error
  }
}

run()
