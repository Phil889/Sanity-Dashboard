import 'dotenv/config'
import { createClient } from '@sanity/client'

// Create client with direct credentials
const client = createClient({
  projectId: 'wwmm9rbb',
  dataset: 'production',
  apiVersion: '2024-02-14',
  token: process.env.SANITY_API_TOKEN,
  useCdn: false,
})

// Helper function to generate unique keys
function generateKey(prefix: string, index: number): string {
  return `${prefix}_${Date.now()}_${index}`
}

const run = async () => {
  try {
    console.log('Updating Basel III Anpassung interner Risikomodelle page with FAQs batch 2 (German)...')
    
    // First, get the existing document
    console.log('Fetching existing document...')
    const existingDoc = await client.fetch('*[_id == $id][0]', { id: 'basel-iii-anpassung-interner-risikomodelle' })
    
    if (!existingDoc) {
      throw new Error('Document "basel-iii-anpassung-interner-risikomodelle" not found')
    }
    
    // Create new FAQs in German
    const newFaqs = [
      {
        _type: 'object',
        _key: generateKey('faq', 1),
        question: "Wie unterscheiden sich die Anforderungen an interne Modelle zwischen Kredit-, Markt- und operationellen Risiken unter Basel III?",
        answer: "Die Basel III-Regulierung differenziert substanziell zwischen den Anforderungen an interne Modelle f√ºr verschiedene Risikoarten. Diese Unterschiede reflektieren die spezifischen Charakteristika und Herausforderungen der jeweiligen Risikokategorien und erfordern ma√ügeschneiderte methodische Ans√§tze und Implementierungsstrategien.\n\nüìä Kreditrisikomodelle (IRB-Ansatz):\n‚Ä¢ Parametrische Fokussierung: Zentrale Bedeutung der Risikoparameter PD (Ausfallwahrscheinlichkeit), LGD (Verlustquote bei Ausfall) und EAD (Exposure at Default) mit spezifischen Kalibrierungsanforderungen f√ºr jeden Parameter.\n‚Ä¢ Downturn-Anforderungen: Besondere Betonung der Notwendigkeit, Rezessionsphasen in die LGD- und EAD-Kalibrierung einzubeziehen, mit pr√§zisen Definitionen f√ºr Downturn-Bedingungen.\n‚Ä¢ Segmentierungsanforderungen: Detaillierte Vorgaben zur Bildung homogener Risikoklassen und Kundensegmente als Grundlage f√ºr die Modellierung.\n‚Ä¢ Datentiefe und -historie: Umfangreiche Anforderungen an die Mindestl√§nge und Qualit√§t historischer Daten, insbesondere f√ºr Low-Default-Portfolios.\n‚Ä¢ Einschr√§nkung des Anwendungsbereichs: Limitierung der Modellierungsm√∂glichkeiten f√ºr bestimmte Exposureklassen wie Aktien, Spezialfinanzierungen und gro√üe Unternehmensexposures.\n\nüìà Marktrisiko-Modelle (IMA-Ansatz):\n‚Ä¢ Mehrkomponentige Metriken: Erweiterung von VaR (Value at Risk) um Expected Shortfall (ES) als prim√§re Risikoma√üzahl, die Verluste im Extrembereich besser erfasst.\n‚Ä¢ Liquidity Horizons: Differenzierte Ber√ºcksichtigung unterschiedlicher Liquidit√§tshorizonte f√ºr verschiedene Risikofaktoren, um realistische Ausstiegszeiten abzubilden.\n‚Ä¢ Non-Modelable Risk Factors: Spezifische Behandlung von Risikofaktoren mit unzureichenden oder niedrigfrequenten Marktdaten durch separate Kapitalzuschl√§ge.\n‚Ä¢ P&L-Attribution: Strenge Anforderungen an die √úbereinstimmung zwischen modelliertem und tats√§chlichem Handelsergebnis als Voraussetzung f√ºr die Modellnutzung.\n‚Ä¢ Stresstestintegration: Systematische Einbindung von Stressszenarien in die Kapitalberechnung, √ºber das reine Backtesting hinaus.\n\n‚öôÔ∏è Operationelle Risikomodelle:\n‚Ä¢ Paradigmenwechsel: Grundlegende Neuausrichtung mit Abschaffung der Advanced Measurement Approach (AMA) zugunsten des standardisierten Measurement Approach (SMA) in Basel III.\n‚Ä¢ Indikatorbasierter Ansatz: Fokussierung auf Gesch√§ftsvolumenindikatoren (Business Indicator) und interne Verlustdaten anstelle komplexer statistischer Modelle.\n‚Ä¢ Verlustdatensammlung: Beibehaltung strenger Anforderungen an die systematische Erfassung interner Verlustereignisse, trotz reduzierter Modellkomplexit√§t.\n‚Ä¢ Qualitative Elemente: Verst√§rkte Betonung qualitativer Risikomanagementprozesse und -kontrollen als Erg√§nzung zu quantitativen Ans√§tzen.\n‚Ä¢ Governance-Fokus: Erh√∂hte Anforderungen an die Governance des operationellen Risikomanagements, mit besonderem Fokus auf die Rolle des Managements.\n\nüîÑ √úbergreifende Entwicklungen und Trends:\n‚Ä¢ Konvergenz zu Standardans√§tzen: Genereller Trend zur Reduzierung der Modellierungsfreiheit und st√§rkeren Orientierung an standardisierten Komponenten √ºber alle Risikoarten hinweg.\n‚Ä¢ Output-Floors: Einf√ºhrung risikoarten√ºbergreifender Untergrenzen f√ºr modellbasierte Kapitalentlastungen im Vergleich zu Standardans√§tzen.\n‚Ä¢ Erh√∂hte Transparenzanforderungen: Versch√§rfte Offenlegungspflichten f√ºr modellbasierte Berechnungen zur Verbesserung der Marktdisziplin und Vergleichbarkeit.\n‚Ä¢ Integrierte Validierung: Zunehmende Anforderungen an die holistische Validierung von Modellen √ºber verschiedene Risikoarten hinweg, besonders bei Interdependenzen.\n‚Ä¢ Technologische Evolution: Erwartung an den Einsatz fortschrittlicher Technologien zur Verbesserung der Datenqualit√§t, Modellperformance und Validierungsprozesse."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 2),
        question: "Welche Rolle spielen fortschrittliche Technologien wie KI und Machine Learning bei der Entwicklung interner Risikomodelle?",
        answer: "K√ºnstliche Intelligenz (KI) und Machine Learning (ML) revolutionieren zunehmend die Entwicklung und Anwendung interner Risikomodelle im Finanzsektor. Diese Technologien bieten signifikante Potenziale zur Verbesserung der Modellgenauigkeit, Effizienz und Risikosensitivit√§t, stellen jedoch gleichzeitig neue Herausforderungen an Governance, Validierung und regulatorische Akzeptanz dar.\n\nüß† Transformative Potenziale von KI/ML in der Risikomodellierung:\n‚Ä¢ Mustererkennungsf√§higkeiten: Identifikation komplexer, nichtlinearer Zusammenh√§nge zwischen Risikofaktoren, die mit traditionellen statistischen Methoden schwer erfassbar sind.\n‚Ä¢ Verarbeitung unstrukturierter Daten: Erschlie√üung neuer Datenquellen wie Textdokumente, Nachrichtenartikel oder Social Media f√ºr die Risikobeurteilung, etwa zur fr√ºhzeitigen Erkennung von Bonit√§tsver√§nderungen.\n‚Ä¢ Automatisierte Feature-Selektion: Algorithmische Identifikation relevanter Risikotreiber aus gro√üen Datens√§tzen, die menschlichen Analysten m√∂glicherweise entgehen w√ºrden.\n‚Ä¢ Adaptive Lernf√§higkeit: Kontinuierliche Modellaktualisierung und -anpassung an ver√§nderte Marktbedingungen ohne vollst√§ndige Neukalibrierung.\n‚Ä¢ Ensemble-Methoden: Kombination multipler Modelle zu robusteren Gesamtprognosen, die einzelne Modellschw√§chen ausgleichen k√∂nnen.\n\nüî¨ Konkrete Anwendungsbereiche in der Risikomodellierung:\n‚Ä¢ Kreditrisikomodellierung: Pr√§zisere Sch√§tzung von Ausfallwahrscheinlichkeiten durch Integration alternativer Datenquellen und Erkennung subtiler Fr√ºhwarnindikatoren f√ºr Bonit√§tsverschlechterungen.\n‚Ä¢ Marktrisikobewertung: Verbesserte Modellierung von Tail-Risiken und nichtlinearen Marktbewegungen sowie fr√ºhzeitige Erkennung von Regimewechseln in Volatilit√§tsmustern.\n‚Ä¢ Betrugserkennung: Echtzeit-Identifikation anomaler Transaktionsmuster und adaptives Lernen neuer Betrugsszenarien ohne explizite Neuprogrammierung.\n‚Ä¢ Stresstestentwicklung: Generierung plausibler, aber herausfordernder Stressszenarien, die historische Erfahrungen mit hypothetischen Marktentwicklungen kombinieren.\n‚Ä¢ Modellvalidierung: Automatisierte Plausibilit√§tspr√ºfungen und Identifikation potenzieller Modellschw√§chen durch systematischen Vergleich mit Benchmark-Modellen.\n\n‚ö†Ô∏è Regulatorische und Governance-Herausforderungen:\n‚Ä¢ Explainability (Erkl√§rbarkeit): Komplexe KI-Modelle wie Deep Learning operieren oft als \"Black Box\", was die regulatorisch geforderte Transparenz und Nachvollziehbarkeit erschwert.\n‚Ä¢ Modellstabilit√§t: KI-Modelle k√∂nnen bei kleinen √Ñnderungen in den Eingabedaten instabil reagieren oder unerwartete Ergebnisse liefern, was besondere Robustheitstests erfordert.\n‚Ä¢ Datenbias: ML-Algorithmen k√∂nnen bestehende Verzerrungen in historischen Daten perpetuieren oder verst√§rken, was zu diskriminierenden oder verzerrten Risikoeinsch√§tzungen f√ºhren kann.\n‚Ä¢ Validierungskomplexit√§t: Die Validierung von KI-Modellen erfordert spezialisierte Expertise und neue Methoden, die in traditionellen Validierungsframeworks nicht ausreichend abgebildet sind.\n‚Ä¢ Regulatorische Akzeptanz: Aufsichtsbeh√∂rden stehen komplexen KI/ML-Modellen teilweise skeptisch gegen√ºber und fordern umfangreiche Nachweise ihrer Verl√§sslichkeit.\n\nüõ†Ô∏è Best Practices f√ºr den erfolgreichen Einsatz von KI/ML:\n‚Ä¢ Hybride Modellierungsans√§tze: Kombination traditioneller statistischer Methoden mit KI-Komponenten f√ºr verbesserte Erkl√§rbarkeit und Robustheit.\n‚Ä¢ Explainable AI (XAI): Einsatz spezieller Techniken wie SHAP-Werte, LIME oder Attention-Mechanismen, die die Entscheidungswege komplexer Modelle transparenter machen.\n‚Ä¢ Extensive Validierungsprozesse: Implementierung umfassender Validierungsverfahren, die speziell auf die Charakteristika von KI-Modellen zugeschnitten sind, einschlie√ülich Stabilit√§tstests und Sensitivit√§tsanalysen.\n‚Ä¢ Strikte Modell-Governance: Etablierung klarer Verantwortlichkeiten und Kontrollen f√ºr den Einsatz von KI-Modellen, mit besonderem Fokus auf ethische Aspekte und Fairness.\n‚Ä¢ Proaktiver Aufsichtsdialog: Fr√ºhzeitige und transparente Kommunikation mit Aufsichtsbeh√∂rden √ºber KI-Anwendungen, idealerweise mit evidenzbasierten Nachweisen ihrer Vorteile."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 3),
        question: "Wie k√∂nnen interne Risikomodelle effektiv in die Gesch√§ftssteuerung integriert werden?",
        answer: "Die effektive Integration interner Risikomodelle in die Gesch√§ftssteuerung ‚Äì h√§ufig als \"Use Test\" bezeichnet ‚Äì stellt eine zentrale Herausforderung f√ºr Finanzinstitute dar. Eine gelungene Integration wandelt Risikomodelle von reinen regulatorischen Compliance-Instrumenten zu wertsch√∂pfenden Steuerungswerkzeugen, die strategische Entscheidungen unterst√ºtzen und zur Wertgenerierung beitragen.\n\nüîó Integrationsbereiche f√ºr wertorientierte Modellnutzung:\n‚Ä¢ Strategie und Portfoliosteuerung: Nutzung von Risikomodellen zur Identifikation optimaler Wachstumsfelder, zur Portfoliodiversifikation und zur Festlegung strategischer Risikoallokationen auf Gesch√§ftsfelder.\n‚Ä¢ Produktentwicklung und Pricing: Integration von Risikoparametern in die Produktkalkulation und Preisgestaltung f√ºr eine risikoadjustierte Renditeoptimierung und Vermeidung adverser Selektion.\n‚Ä¢ Kreditentscheidungsprozesse: Einbindung modellbasierter Risikoeinsch√§tzungen in Kreditvergabeentscheidungen, Limitfestlegungen und Besicherungsanforderungen.\n‚Ä¢ Performance-Messung: Implementierung risikoadjustierter Performance-Kennzahlen wie RAROC (Risk-Adjusted Return on Capital) oder EVA (Economic Value Added) f√ºr eine wertorientierte Steuerung.\n‚Ä¢ Verg√ºtungssysteme: Verkn√ºpfung von variablen Verg√ºtungskomponenten mit risikoadjustierten Leistungskennzahlen zur F√∂rderung nachhaltiger Gesch√§ftsentscheidungen.\n\nüõ†Ô∏è Praktische Implementierungsans√§tze:\n‚Ä¢ Top-Down Commitment: Verankerung der risikobasierten Steuerung in der Unternehmensstrategie und aktives Vorleben durch Vorstand und oberes Management als Voraussetzung f√ºr kulturelle Akzeptanz.\n‚Ä¢ Integrierte IT-Architektur: Entwicklung einer koh√§renten Systemlandschaft, die nahtlose Informationsfl√ºsse zwischen Risiko-, Finanz- und Frontoffice-Systemen erm√∂glicht und Dateninkonsistenzen minimiert.\n‚Ä¢ Konsistente Risikosprache: Etablierung einer einheitlichen Risikotaxonomie und -metrik √ºber alle Gesch√§ftsbereiche und Managementebenen hinweg, um Kommunikationsbarrieren zu reduzieren.\n‚Ä¢ Risiko-KPIs: Definition verst√§ndlicher, handlungsorientierter Risikokennzahlen, die auf Gesch√§ftsebene operationalisierbar sind und in regul√§re Management-Reportings integriert werden.\n‚Ä¢ Schulungs- und Change-Management: Systematische F√∂rderung des Risikoverst√§ndnisses bei Entscheidungstr√§gern aller Ebenen durch zielgruppenspezifische Schulungen und kontinuierliche Kommunikation.\n\nüìà Konkrete Business-Use-Cases f√ºr Risikomodelle:\n‚Ä¢ Customer Lifetime Value unter Risikoaspekten: Erweiterung klassischer CLV-Betrachtungen um erwartete Kreditverluste und Kapitalkosten f√ºr eine ganzheitliche Kundenrentabilit√§tsanalyse.\n‚Ä¢ Risk-based Pricing: Differenzierung von Konditionen basierend auf individuellen Risikoprofilen und regulatorischen Kapitalanforderungen f√ºr eine marktgerechte und risikoad√§quate Preisgestaltung.\n‚Ä¢ Portfolio-Optimierung: Identifikation optimaler Portfoliozusammensetzungen unter Ber√ºcksichtigung von Risiko-Rendite-Profilen, regulatorischen Beschr√§nkungen und strategischen Zielen.\n‚Ä¢ Early Warning Systems: Fr√ºhzeitige Erkennung sich verschlechternder Kreditengagements durch modellbasierte Indikatoren als Grundlage f√ºr pr√§ventive Ma√ünahmen.\n‚Ä¢ Stresstestbasierte Gesch√§ftsplanung: Integration von Stresstergebnissen in die strategische und operative Planung zur Erh√∂hung der organisationalen Resilienz.\n\n‚ö° Erfolgsfaktoren und Hindernisse:\n‚Ä¢ Modellrelevanz und -qualit√§t: Sicherstellung, dass Modelle gesch√§ftsrelevante Risiken pr√§zise und zeitnah abbilden, als Grundvoraussetzung f√ºr ihre Akzeptanz im Gesch√§ftsbereich.\n‚Ä¢ Anwenderfreundlichkeit: Bereitstellung intuitiver Interfaces und verst√§ndlicher Interpretationshilfen f√ºr Modellergebnisse, die auch von Nicht-Spezialisten effektiv genutzt werden k√∂nnen.\n‚Ä¢ Modelltransparenz: F√∂rderung des Verst√§ndnisses f√ºr Modellannahmen, -st√§rken und -grenzen bei allen Stakeholdern, um √ºberm√§√üiges Vertrauen oder unbegr√ºndete Skepsis zu vermeiden.\n‚Ä¢ Kulturelle Barrieren: √úberwindung traditioneller Silostrukturen und F√∂rderung einer risikobewussten Unternehmenskultur auf allen Hierarchieebenen.\n‚Ä¢ Regulatory Compliance vs. Business Value: Ausbalancierung regulatorischer Anforderungen und gesch√§ftlicher Nutzenpotenziale bei der Modellkonzeption und -weiterentwicklung."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 4),
        question: "Welche Datenmanagement-Strategien unterst√ºtzen die erfolgreiche Implementierung interner Risikomodelle?",
        answer: "Die Qualit√§t und Verf√ºgbarkeit von Daten ist ein fundamentaler Erfolgsfaktor f√ºr die Entwicklung, Implementierung und kontinuierliche Verbesserung interner Risikomodelle. Eine durchdachte Datenmanagement-Strategie bildet das Fundament f√ºr pr√§zise, robuste und aufsichtskonforme Modelle und gewinnt unter Basel III weiter an Bedeutung.\n\nüîÑ Kernelemente eines modellorientierten Datenmanagements:\n‚Ä¢ Data Governance: Etablierung klarer Verantwortlichkeiten, Prozesse und Kontrollen f√ºr die Sicherstellung von Datenqualit√§t, -konsistenz und -integrit√§t √ºber den gesamten Datenlebenszyklus.\n‚Ä¢ Datenarchitektur: Konzeption einer flexiblen, skalierbaren Dateninfrastruktur, die sowohl aktuelle Modellanforderungen erf√ºllt als auch zuk√ºnftige Erweiterungen erm√∂glicht.\n‚Ä¢ Metadatenmanagement: Systematische Erfassung und Verwaltung von Informationen √ºber Datenherkunft, -definitionen, -transformationen und -verwendung zur F√∂rderung von Transparenz und Nachvollziehbarkeit.\n‚Ä¢ Data Lineage: Dokumentation des vollst√§ndigen Datenflusses von der Quelle bis zur Modellverwendung, einschlie√ülich aller Transformationen und Berechnungen, zur Unterst√ºtzung von Audit-Anforderungen.\n‚Ä¢ Datenqualit√§tsmanagement: Implementierung umfassender Kontrollen und Kennzahlen zur kontinuierlichen √úberwachung und Verbesserung der Datenqualit√§t entlang definierter Dimensionen.\n\nüìä Spezifische Datenanforderungen f√ºr Risikomodelle:\n‚Ä¢ Historische Tiefe: Aufbau ausreichend langer Zeitreihen, die mindestens einen vollst√§ndigen Wirtschaftszyklus abdecken und insbesondere Downturn-Phasen enthalten, wie von Basel III explizit gefordert.\n‚Ä¢ Granularit√§t: Sammlung und Speicherung von Daten auf Einzelpositionsebene, um flexible Aggregationen und differenzierte Analysen zu erm√∂glichen.\n‚Ä¢ Vollst√§ndigkeit: Minimierung von Datenl√ºcken durch proaktive Datenerhebungsstrategien und dokumentierte Prozesse zum Umgang mit fehlenden Werten.\n‚Ä¢ Konsistenz: Sicherstellung einheitlicher Definitionen, Berechnungsmethoden und Datenformate √ºber verschiedene Systeme und Gesch√§ftsbereiche hinweg.\n‚Ä¢ Aktualit√§t: Implementierung effizienter Prozesse zur zeitnahen Datenaktualisierung und Reduzierung von Latenzzeiten zwischen Datenereignissen und deren Verf√ºgbarkeit f√ºr Modelle.\n\n‚öôÔ∏è Technologische Enabler und Architekturen:\n‚Ä¢ Data Lakes und Big Data Technologien: Nutzung skalierbarer Plattformen zur kosteneffizienten Speicherung und Verarbeitung gro√üer, heterogener Datenmengen verschiedener Strukturierungsgrade.\n‚Ä¢ Enterprise Data Warehouse: Implementierung integrierter, themenorientierter Datenbest√§nde mit konsistenten Definitionen als Single Point of Truth f√ºr Risikomodelle.\n‚Ä¢ Master Data Management: Etablierung zentraler Stammdatensysteme zur Sicherstellung konsistenter Referenzdaten wie Kunden-, Kontrahenten- oder Produktinformationen.\n‚Ä¢ Data Virtualization: Einsatz von Technologien zur logischen Integration verteilter Datenquellen ohne physische Replikation, um Flexibilit√§t zu erh√∂hen und Redundanzen zu reduzieren.\n‚Ä¢ Cloud-basierte L√∂sungen: Nutzung elastischer Cloud-Infrastrukturen f√ºr skalierbare Datenspeicherung und -verarbeitung, insbesondere f√ºr rechenintensive Modellsimulationen und Szenarioanalysen.\n\nüõ°Ô∏è Regulatorische Aspekte und Datenschutz:\n‚Ä¢ BCBS 239 Compliance: Erf√ºllung der Grunds√§tze f√ºr eine effektive Risikodatenaggregation und -berichterstattung, die eng mit den Datenanforderungen f√ºr interne Modelle verzahnt sind.\n‚Ä¢ Datenschutz by Design: Integration von Datenschutzanforderungen bereits in die Konzeptionsphase von Datenarchitekturen und Modellierungsprozessen, besonders relevant f√ºr personenbezogene Daten in Kreditrisikomodellen.\n‚Ä¢ Audit Trails: Implementierung l√ºckenloser Nachverfolgungsmechanismen f√ºr Datenver√§nderungen zur Unterst√ºtzung von Pr√ºfungs- und Validierungsaktivit√§ten.\n‚Ä¢ Dokumentationsstandards: Entwicklung umfassender Dokumentation zu Datenquellen, -definitionen, -qualit√§t und -limitationen als integraler Bestandteil der Modellierungsdokumentation.\n‚Ä¢ Notfallplanung: Etablierung robuster Business Continuity Pl√§ne f√ºr kritische Dateninfrastrukturen, um die kontinuierliche Verf√ºgbarkeit f√ºr Risikomodelle sicherzustellen."
      }
    ]
    
    // Update the document with new FAQs
    const updatedFaqs = [...(existingDoc.faq || []), ...newFaqs]
    
    console.log(`Adding ${newFaqs.length} new FAQs (German) to the document...`)
    const transaction = client.transaction()
    transaction.patch(existingDoc._id, {
      set: {
        faq: updatedFaqs
      }
    })
    
    await transaction.commit()
    console.log('‚úÖ FAQs batch 2 (German) added successfully')
  } catch (error) {
    console.error('Error:', error)
    throw error
  }
}

run()
