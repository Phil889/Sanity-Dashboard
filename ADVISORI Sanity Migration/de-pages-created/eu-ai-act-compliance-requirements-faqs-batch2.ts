import 'dotenv/config'
import { createClient } from '@sanity/client'

// Create client with direct credentials
const client = createClient({
  projectId: 'wwmm9rbb',
  dataset: 'production',
  apiVersion: '2024-02-14',
  token: process.env.SANITY_API_TOKEN,
  useCdn: false,
})

// Helper function to generate unique keys
function generateKey(prefix: string, index: number): string {
  return `${prefix}_${Date.now()}_${index}`
}

const run = async () => {
  try {
    console.log('Updating EU AI Act Compliance Requirements page with C-Level FAQs batch 2 (German)...')
    
    // First, get the existing document
    console.log('Fetching existing document...')
    const existingDoc = await client.fetch('*[_id == $id][0]', { id: 'eu-ai-act-compliance-requirements' })
    
    if (!existingDoc) {
      throw new Error('Document "eu-ai-act-compliance-requirements" not found')
    }
    
    // Create new C-Level FAQs in German
    const newFaqs = [
      {
        _type: 'object',
        _key: generateKey('faq', 5),
        question: "Welche spezifischen Dokumentations- und Nachweispflichten ergeben sich aus dem EU AI Act und wie k√∂nnen wir diese systematisch erf√ºllen?",
        answer: "Die Dokumentations- und Nachweispflichten des EU AI Act sind umfangreich und bilden das R√ºckgrat einer erfolgreichen Compliance-Strategie. Sie dienen nicht nur der regulatorischen Erf√ºllung, sondern auch als strategisches Instrument zur Qualit√§tssicherung und Risikominimierung in der KI-Entwicklung und -Anwendung.\n\nüìã Zentrale Dokumentationsanforderungen des EU AI Act:\n‚Ä¢ Qualit√§tsmanagementsystem-Dokumentation: Vollst√§ndige Beschreibung der QMS-Prozesse, Verantwortlichkeiten und Kontrollmechanismen f√ºr alle Hochrisiko-KI-Systeme.\n‚Ä¢ Technische Dokumentation: Detaillierte Spezifikationen zu Systemarchitektur, Datenqualit√§t, Algorithmen, Testverfahren und Leistungsmetriken.\n‚Ä¢ Risikoanalyse und -bewertung: Systematische Erfassung und Bewertung aller identifizierten Risiken mit entsprechenden Minderungsma√ünahmen.\n‚Ä¢ Transparenz- und Nutzerinformationen: Klare, verst√§ndliche Dokumentation der Systemfunktionalit√§ten und Limitationen f√ºr Endnutzer.\n‚Ä¢ √Ñnderungsprotokoll: Vollst√§ndige Nachverfolgung aller Systemmodifikationen mit Impact-Analysen und Compliance-Bewertungen.\n\nüèóÔ∏è ADVISORIs systematischer Dokumentationsansatz:\n‚Ä¢ Automatisierte Dokumentationssysteme: Implementierung digitaler Plattformen, die Dokumentationsprozesse automatisieren und kontinuierlich aktuell halten.\n‚Ä¢ Template-basierte Standardisierung: Entwicklung wiederverwendbarer Dokumentationsvorlagen, die Konsistenz sicherstellen und Effizienz steigern.\n‚Ä¢ Integrierte Compliance-Workflows: Verbindung der Dokumentationsanforderungen mit bestehenden Entwicklungs- und Qualit√§tssicherungsprozessen.\n‚Ä¢ Audit-ready Strukturierung: Aufbau der Dokumentation mit explizitem Fokus auf Pr√ºfbarkeit und regulatorische Nachweisf√ºhrung."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 6),
        question: "Wie unterscheiden sich die Compliance-Anforderungen f√ºr Foundation Models und GPAI-Systeme von herk√∂mmlichen KI-Anwendungen?",
        answer: "Foundation Models und General Purpose AI (GPAI)-Systeme unterliegen spezifischen, versch√§rften Anforderungen unter dem EU AI Act, die ihre systemische Bedeutung und das potentielle Risiko f√ºr die Gesellschaft widerspiegeln. Diese erweiterten Verpflichtungen erfordern eine spezialisierte Compliance-Strategie, die √ºber traditionelle KI-Governance hinausgeht.\n\nüî¨ Spezifische Anforderungen f√ºr Foundation Models und GPAI:\n‚Ä¢ Systemische Risikobewertung: Umfassende Analyse der gesellschaftlichen und wirtschaftlichen Auswirkungen mit besonderem Fokus auf systemische Risiken und Cascade-Effekte.\n‚Ä¢ Erweiterte Cybersecurity-Ma√ünahmen: Implementierung robuster Sicherheitsarchitekturen zum Schutz vor Missbrauch, Manipulation und adversariellen Angriffen.\n‚Ä¢ Model Governance Excellence: Aufbau spezialisierter Governance-Strukturen f√ºr Modellentwicklung, -validierung, -deployment und -monitoring.\n‚Ä¢ Kontinuierliches Monitoring: Etablierung fortlaufender √úberwachungssysteme f√ºr Modellverhalten, Performance-Drift und unerwartete Emergent Properties.\n‚Ä¢ Stakeholder-Engagement: Proaktive Kommunikation mit Regulatoren, Forschungsgemeinschaft und Zivilgesellschaft √ºber Modellentwicklungen und -risiken.\n\n‚ö° Differenzierung zu Standard-KI-Systemen:\n‚Ä¢ H√∂here Transparenzanforderungen: Foundation Models m√ºssen deutlich umfangreichere Informationen √ºber Training, Daten und Capabilities offenlegen.\n‚Ä¢ Pr√§ventive Risikoanalyse: W√§hrend Standard-KI-Systeme reaktive Risikobewertung erfordern, m√ºssen GPAI-Systeme proaktive, hypothetische Risikoanalysen durchf√ºhren.\n‚Ä¢ Erweiterte Testing-Verpflichtungen: Systematische Evaluation auf Bias, Fairness, Robustheit und potentielle Dual-Use-Risiken.\n\nüöÄ ADVISORIs spezialisierter GPAI-Compliance-Ansatz:\n‚Ä¢ Advanced Model Governance: Entwicklung hochspezialisierter Governance-Frameworks, die den einzigartigen Herausforderungen von Foundation Models gerecht werden.\n‚Ä¢ Regulatory Technology Integration: Einsatz modernster RegTech-L√∂sungen f√ºr kontinuierliches Monitoring und automatisierte Compliance-√úberwachung.\n‚Ä¢ Multi-Stakeholder Engagement: Aufbau strukturierter Kommunikationskan√§le mit Regulatoren und anderen relevanten Stakeholdern zur proaktiven Risikokommunikation."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 7),
        question: "Welche Rolle spielt menschliche Aufsicht bei EU AI Act-Compliance und wie implementieren wir diese effektiv in unsere KI-Systeme?",
        answer: "Menschliche Aufsicht (Human Oversight) ist ein Kernprinzip des EU AI Act und erfordert eine durchdachte Integration in KI-Systeme, die sowohl regulatorische Anforderungen erf√ºllt als auch praktische Anwendbarkeit gew√§hrleistet. Die effektive Implementierung menschlicher Aufsicht kann gleichzeitig Compliance sicherstellen und die Qualit√§t von KI-Entscheidungen verbessern.\n\nüë• Dimensionen menschlicher Aufsicht im EU AI Act:\n‚Ä¢ Human-in-the-Loop: Direkte menschliche Beteiligung an kritischen KI-Entscheidungen mit Interventionsm√∂glichkeiten in Echtzeit.\n‚Ä¢ Human-on-the-Loop: Kontinuierliche menschliche √úberwachung von KI-Systemen mit der F√§higkeit zur nachtr√§glichen Korrektur und Anpassung.\n‚Ä¢ Human-in-Command: √úbergeordnete menschliche Kontrolle √ºber KI-Systeme mit finaler Entscheidungsautorit√§t und Verantwortung.\n‚Ä¢ Meaningful Human Control: Gew√§hrleistung, dass menschliche Aufsichtspersonen tats√§chlich verstehen, beeinflussen und kontrollieren k√∂nnen, was das KI-System tut.\n\nüîß Praktische Implementierungsstrategien:\n‚Ä¢ Risikoproportionale Gestaltung: Anpassung der Intensit√§t menschlicher Aufsicht an das Risikolevel und die Kriticalit√§t der KI-Anwendung.\n‚Ä¢ User Interface Excellence: Entwicklung intuitiver Interfaces, die menschlichen Aufsichtspersonen alle relevanten Informationen verst√§ndlich pr√§sentieren.\n‚Ä¢ Training und Kompetenzaufbau: Systematische Schulung der Aufsichtspersonen in KI-Verst√§ndnis, Risikobewertung und Interventionsmethoden.\n‚Ä¢ Prozessintegration: Nahtlose Einbettung der Aufsichtsmechanismen in bestehende Gesch√§ftsprozesse ohne √ºberm√§√üige Effizienzeinbu√üen.\n\n‚öôÔ∏è ADVISORIs Human Oversight Implementation:\n‚Ä¢ Adaptive Oversight-Systeme: Entwicklung intelligenter √úberwachungssysteme, die die Intensit√§t menschlicher Aufsicht dynamisch an Kontext und Risiko anpassen.\n‚Ä¢ Decision Support Integration: Implementierung fortschrittlicher Decision-Support-Systeme, die menschliche Aufsichtspersonen optimal informieren und unterst√ºtzen.\n‚Ä¢ Performance Monitoring: Aufbau von Systemen zur kontinuierlichen Bewertung der Effektivit√§t menschlicher Aufsicht und deren kontinuierliche Verbesserung.\n‚Ä¢ Compliance-by-Design: Integration von Human Oversight-Anforderungen bereits in die Systemarchitektur zur Vermeidung nachtr√§glicher kostspieliger Anpassungen."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 8),
        question: "Wie stellen wir sicher, dass unsere KI-Systeme die Datenqualit√§ts- und Bias-Minimierungsanforderungen des EU AI Act erf√ºllen?",
        answer: "Datenqualit√§t und Bias-Minimierung sind fundamentale S√§ulen des EU AI Act und erfordern eine systematische, technologiegest√ºtzte Herangehensweise, die bereits in der Datensammlung beginnt und sich durch den gesamten KI-Lebenszyklus zieht. Eine proaktive Strategie kann nicht nur Compliance sicherstellen, sondern auch die Qualit√§t und Fairness von KI-Systemen erheblich verbessern.\n\nüìä Zentrale Datenqualit√§tsanforderungen des EU AI Act:\n‚Ä¢ Repr√§sentativit√§t und Vollst√§ndigkeit: Sicherstellung, dass Trainingsdaten alle relevanten Anwendungsszenarien und Bev√∂lkerungsgruppen angemessen abbilden.\n‚Ä¢ Accuracy und Konsistenz: Implementierung robuster Validierungsprozesse zur Gew√§hrleistung der Datengenauigkeit und -konsistenz.\n‚Ä¢ Relevanz und Aktualit√§t: Etablierung von Prozessen zur kontinuierlichen Bewertung und Aktualisierung der Datenrelevanz f√ºr den Anwendungskontext.\n‚Ä¢ Bias-Detection und -Mitigation: Systematische Identifikation und Reduzierung von Verzerrungen in Daten und Algorithmen.\n‚Ä¢ Dokumentation und Nachvollziehbarkeit: Vollst√§ndige Dokumentation der Datenherkunft, -verarbeitung und -qualit√§tskontrolle.\n\nüîç Strategien zur Bias-Minimierung:\n‚Ä¢ Multi-dimensionale Fairness-Analyse: Bewertung von KI-Systemen hinsichtlich verschiedener Fairness-Metriken und demografischer Dimensionen.\n‚Ä¢ Adversarial Testing: Systematische Tests auf robustheit gegen√ºber verschiedenen Arten von Bias und diskriminierenden Outcomes.\n‚Ä¢ Kontinuierliches Monitoring: Implementierung fortlaufender √úberwachung von KI-Outputs auf Anzeichen von Bias oder unfairer Behandlung.\n‚Ä¢ Diverse Entwicklungsteams: F√∂rderung diverser, multidisziplin√§rer Teams zur Reduzierung unbewusster Voreingenommenheit in der Systementwicklung.\n\n‚öóÔ∏è ADVISORIs Data Excellence Approach:\n‚Ä¢ Automated Data Quality Assurance: Implementierung automatisierter Systeme zur kontinuierlichen Datenqualit√§tskontrolle und -verbesserung.\n‚Ä¢ AI-powered Bias Detection: Einsatz fortschrittlicher KI-Tools zur proaktiven Identifikation und Quantifizierung von Bias in Daten und Modellen.\n‚Ä¢ Synthetic Data Generation: Strategische Nutzung synthetischer Daten zur Verbesserung der Datenrepr√§sentativit√§t und Bias-Reduzierung.\n‚Ä¢ Federated Learning Integration: Implementierung f√∂derierter Lernans√§tze zur Verbesserung der Datenqualit√§t bei gleichzeitigem Datenschutz."
      }
    ]
    
    // Update the document with new FAQs
    const updatedFaqs = [...(existingDoc.faq || []), ...newFaqs]
    
    console.log(`Adding ${newFaqs.length} new C-Level FAQs (German) to the document...`)
    const transaction = client.transaction()
    transaction.patch(existingDoc._id, {
      set: {
        faq: updatedFaqs
      }
    })
    
    await transaction.commit()
    console.log('‚úÖ C-Level FAQs batch 2 (German) added successfully')
  } catch (error) {
    console.error('Error:', error)
    throw error
  }
}

run()
