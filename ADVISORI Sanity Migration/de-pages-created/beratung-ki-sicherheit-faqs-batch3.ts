import 'dotenv/config'
import { createClient } from '@sanity/client'

// Create client with direct credentials
const client = createClient({
  projectId: 'wwmm9rbb',
  dataset: 'production',
  apiVersion: '2024-02-14',
  token: process.env.SANITY_API_TOKEN,
  useCdn: false,
})

// Helper function to generate unique keys
function generateKey(prefix: string, index: number): string {
  return `${prefix}_${Date.now()}_${index}`
}

const run = async () => {
  try {
    console.log('Updating Beratung KI-Sicherheit page with FAQs batch 3...')
    
    // First, get the existing document
    console.log('Fetching existing document...')
    const existingDoc = await client.fetch('*[_id == $id][0]', { id: 'beratung-ki-sicherheit' })
    
    if (!existingDoc) {
      throw new Error('Document "beratung-ki-sicherheit" not found')
    }
    
    // Create new FAQs
    const newFaqs = [
      {
        _type: 'object',
        _key: generateKey('faq', 9),
        question: 'Wie k√∂nnen Unternehmen ihre AI-Supply-Chain absichern und welche Risiken entstehen durch Third-Party AI-Services und -Modelle?',
        answer: "Die AI-Supply-Chain stellt eine oft √ºbersehene, aber kritische Sicherheitsdimension dar, da Unternehmen zunehmend auf externe AI-Services, Pre-trained Models und Third-Party-Komponenten angewiesen sind. Diese Abh√§ngigkeiten k√∂nnen erhebliche Sicherheitsrisiken schaffen, die √ºber traditionelle Vendor-Management-Ans√§tze hinausgehen. ADVISORI entwickelt umfassende AI-Supply-Chain-Security-Strategien, die diese komplexen Risiken adressieren.\n\nüîó AI-Supply-Chain Vulnerabilities:\n‚Ä¢ Model Provenance und Integrity: Sicherstellung der Authentizit√§t und Integrit√§t von Third-Party AI-Modellen, einschlie√ülich Verifikation der Trainingsverfahren und Datenquellen.\n‚Ä¢ Dependency Vulnerabilities: Identifikation und Management von Sicherheitsl√ºcken in AI-Frameworks, Bibliotheken und Dependencies, die in der gesamten AI-Pipeline verwendet werden.\n‚Ä¢ Vendor Lock-in Risks: Bewertung und Mitigation von Risiken, die durch √ºberm√§√üige Abh√§ngigkeit von einzelnen AI-Service-Providern entstehen.\n‚Ä¢ Data Sovereignty Concerns: Gew√§hrleistung der Kontrolle √ºber sensible Daten bei der Nutzung externer AI-Services und Cloud-basierter ML-Plattformen.\n\nüõ°Ô∏è ADVISORI's Supply Chain Security Framework:\n‚Ä¢ Comprehensive Vendor Assessment: Entwicklung spezialisierter Bewertungskriterien f√ºr AI-Vendor, die √ºber traditionelle IT-Security-Assessments hinausgehen und AI-spezifische Risiken ber√ºcksichtigen.\n‚Ä¢ Model Validation und Testing: Implementierung rigoroser Testverfahren f√ºr externe AI-Modelle, einschlie√ülich Adversarial Testing und Performance Validation.\n‚Ä¢ Secure Integration Patterns: Entwicklung sicherer Architekturmuster f√ºr die Integration externer AI-Services, die Isolation und Kontrolle gew√§hrleisten.\n‚Ä¢ Continuous Supply Chain Monitoring: Etablierung kontinuierlicher √úberwachung der AI-Supply-Chain auf Sicherheitsupdates, Vulnerabilities und Compliance-√Ñnderungen."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 10),
        question: 'Welche spezifischen Sicherheitsanforderungen gelten f√ºr AI-Systeme in regulierten Branchen und wie unterst√ºtzt ADVISORI bei der Compliance?',
        answer: "Regulierte Branchen wie Finanzdienstleistungen, Gesundheitswesen und Automobilindustrie stehen vor besonderen Herausforderungen bei der sicheren Implementierung von AI-Systemen. Diese Sektoren m√ºssen nicht nur allgemeine AI-Sicherheitsstandards erf√ºllen, sondern auch branchenspezifische Regulierungen beachten. ADVISORI entwickelt ma√ügeschneiderte Compliance-Strategien, die sowohl Innovation erm√∂glichen als auch regulatorische Anforderungen vollst√§ndig erf√ºllen.\n\nüìã Branchenspezifische AI-Compliance-Anforderungen:\n‚Ä¢ Financial Services: Einhaltung von Basel III, MiFID II und anderen Finanzregulierungen bei AI-gest√ºtzten Trading-Algorithmen, Kreditentscheidungen und Risikobewertungen.\n‚Ä¢ Healthcare: Compliance mit HIPAA, FDA-Richtlinien und Medizinproduktegesetzen f√ºr AI-basierte Diagnose- und Behandlungssysteme.\n‚Ä¢ Automotive: Erf√ºllung von ISO 26262 und anderen Sicherheitsstandards f√ºr AI in autonomen Fahrzeugen und Fahrerassistenzsystemen.\n‚Ä¢ Critical Infrastructure: Beachtung von NIS2, KRITIS und anderen Schutzvorschriften f√ºr AI in kritischen Infrastrukturen.\n\nüèõÔ∏è ADVISORI's Regulatory Compliance Approach:\n‚Ä¢ Sector-Specific Expertise: Tiefes Verst√§ndnis f√ºr die regulatorischen Landschaften verschiedener Branchen und deren spezifische AI-Anforderungen.\n‚Ä¢ Compliance-by-Design: Integration regulatorischer Anforderungen in den AI-Entwicklungsprozess von Anfang an, nicht als nachgelagerte Compliance-√úbung.\n‚Ä¢ Audit-Ready Documentation: Entwicklung umfassender Dokumentationsstandards, die regulatorische Audits und Inspektionen unterst√ºtzen.\n‚Ä¢ Regulatory Change Management: Kontinuierliche √úberwachung regulatorischer Entwicklungen und proaktive Anpassung der AI-Systeme an neue Anforderungen."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 11),
        question: 'Wie implementiert ADVISORI Zero-Trust-Prinzipien f√ºr AI-Infrastrukturen und welche besonderen Herausforderungen entstehen dabei?',
        answer: "Zero-Trust-Architekturen f√ºr AI-Infrastrukturen erfordern einen grundlegend anderen Ansatz als traditionelle Zero-Trust-Implementierungen, da AI-Systeme einzigartige Vertrauens- und Verifikationsherausforderungen mit sich bringen. ADVISORI entwickelt spezialisierte Zero-Trust-Frameworks, die die dynamische Natur von AI-Workloads ber√ºcksichtigen und gleichzeitig h√∂chste Sicherheitsstandards gew√§hrleisten.\n\nüîí Zero-Trust Challenges f√ºr AI-Systeme:\n‚Ä¢ Dynamic Trust Evaluation: Entwicklung von Mechanismen zur kontinuierlichen Bewertung der Vertrauensw√ºrdigkeit von AI-Modellen und deren Entscheidungen in Echtzeit.\n‚Ä¢ Model Identity und Authentication: Implementierung robuster Identit√§ts- und Authentifizierungssysteme f√ºr AI-Modelle, die √ºber traditionelle User-Authentication hinausgehen.\n‚Ä¢ Data Flow Verification: Kontinuierliche Verifikation und Autorisierung von Datenfl√ºssen zwischen verschiedenen AI-Komponenten und -Services.\n‚Ä¢ Micro-Segmentation f√ºr AI: Entwicklung granularer Netzwerksegmentierung, die AI-spezifische Kommunikationsmuster und -anforderungen ber√ºcksichtigt.\n\nüõ°Ô∏è ADVISORI's Zero-Trust AI Architecture:\n‚Ä¢ Continuous Model Verification: Implementierung kontinuierlicher Verifikationsprozesse f√ºr AI-Modelle, die deren Integrit√§t und Performance in Echtzeit √ºberwachen.\n‚Ä¢ Least Privilege f√ºr AI: Anwendung von Least-Privilege-Prinzipien auf AI-Systeme, einschlie√ülich granularer Zugriffskontrolle auf Daten, Modelle und Compute-Ressourcen.\n‚Ä¢ Encrypted AI Pipelines: End-to-End-Verschl√ºsselung von AI-Datenverarbeitungspipelines, einschlie√ülich Homomorphic Encryption f√ºr Privacy-Preserving AI.\n‚Ä¢ Behavioral Analytics f√ºr AI: Einsatz von Behavioral Analytics zur Erkennung anomaler Aktivit√§ten in AI-Systemen und automatische Anpassung von Trust-Levels."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 12),
        question: 'Welche Rolle spielt Incident Response bei AI-Sicherheitsvorf√§llen und wie entwickelt ADVISORI spezialisierte Response-Strategien?',
        answer: "AI-Sicherheitsvorf√§lle erfordern spezialisierte Incident Response-Strategien, die √ºber traditionelle Cybersecurity-Reaktionspl√§ne hinausgehen. AI-spezifische Vorf√§lle k√∂nnen subtil sein, schwer zu erkennen und komplexe Auswirkungen auf Gesch√§ftsprozesse haben. ADVISORI entwickelt ma√ügeschneiderte AI-Incident-Response-Frameworks, die schnelle Erkennung, effektive Eind√§mmung und vollst√§ndige Wiederherstellung gew√§hrleisten.\n\nüö® AI-Specific Incident Types:\n‚Ä¢ Model Compromise: Erkennung und Reaktion auf kompromittierte AI-Modelle, einschlie√ülich Backdoor-Angriffe und Model Poisoning.\n‚Ä¢ Data Leakage Incidents: Spezielle Verfahren f√ºr Vorf√§lle, bei denen AI-Systeme unbeabsichtigt sensible Informationen preisgeben.\n‚Ä¢ Adversarial Attack Response: Schnelle Identifikation und Neutralisierung von Adversarial Attacks auf produktive AI-Systeme.\n‚Ä¢ AI System Failures: Reaktion auf kritische AI-Systemausf√§lle, die Gesch√§ftsprozesse beeintr√§chtigen oder Sicherheitsrisiken schaffen.\n\nüîÑ ADVISORI's AI Incident Response Framework:\n‚Ä¢ Specialized Detection Capabilities: Entwicklung AI-spezifischer Erkennungssysteme, die subtile Anomalien und Angriffe identifizieren k√∂nnen, die traditionelle Security Tools √ºbersehen.\n‚Ä¢ Rapid Containment Strategies: Implementierung schneller Eind√§mmungsverfahren f√ºr AI-Vorf√§lle, einschlie√ülich Model Isolation und Rollback-Mechanismen.\n‚Ä¢ Forensic Analysis f√ºr AI: Spezialisierte forensische Verfahren zur Analyse von AI-Vorf√§llen, einschlie√ülich Model Archaeology und Data Provenance Tracking.\n‚Ä¢ Recovery und Lessons Learned: Systematische Wiederherstellungsprozesse und Post-Incident-Analysen zur kontinuierlichen Verbesserung der AI-Sicherheitsposture."
      }
    ]
    
    // Update the document with new FAQs
    const updatedFaqs = [...(existingDoc.faq || []), ...newFaqs]
    
    console.log(`Adding ${newFaqs.length} new FAQs to the document...`)
    const transaction = client.transaction()
    transaction.patch(existingDoc._id, {
      set: {
        faq: updatedFaqs
      }
    })
    
    await transaction.commit()
    console.log('‚úÖ FAQs batch 3 added successfully')
  } catch (error) {
    console.error('Error:', error)
    throw error
  }
}

run()
