import 'dotenv/config'
import { createClient } from '@sanity/client'

// Create client with direct credentials
const client = createClient({
  projectId: 'wwmm9rbb',
  dataset: 'production',
  apiVersion: '2024-02-14',
  token: process.env.SANITY_API_TOKEN,
  useCdn: false,
})

// Helper function to generate unique keys
function generateKey(prefix: string, index: number): string {
  return `${prefix}_${Date.now()}_${index}`
}

const run = async () => {
  try {
    console.log('Updating Datensicherheit f√ºr KI page with FAQs batch 1...')
    
    // First, get the existing document
    console.log('Fetching existing document...')
    const existingDoc = await client.fetch('*[_id == $id][0]', { id: 'datensicherheit-fuer-ki' })
    
    if (!existingDoc) {
      throw new Error('Document "datensicherheit-fuer-ki" not found')
    }
    
    // Create new FAQs
    const newFaqs = [
      {
        _type: 'object',
        _key: generateKey('faq', 1),
        question: 'Warum ist Datensicherheit in KI-Systemen komplexer als traditioneller Datenschutz und welche spezifischen Herausforderungen entstehen durch Machine Learning?',
        answer: "Datensicherheit in KI-Systemen bringt einzigartige Komplexit√§ten mit sich, die weit √ºber traditionelle Datenschutzma√ünahmen hinausgehen. Machine Learning Systeme verarbeiten nicht nur gro√üe Datenmengen, sondern k√∂nnen auch unbeabsichtigt sensible Informationen durch Modellverhalten preisgeben oder durch adversarielle Angriffe kompromittiert werden. Die dynamische Natur von KI-Systemen erfordert kontinuierliche Sicherheits√ºberwachung und adaptive Schutzma√ünahmen.\n\nüîç Spezifische Herausforderungen in KI-Datensicherheit:\n‚Ä¢ Model Inversion Attacks: Angreifer k√∂nnen aus Modellausgaben auf Trainingsdaten schlie√üen und sensible Informationen extrahieren, selbst wenn die urspr√ºnglichen Daten nie direkt zug√§nglich waren.\n‚Ä¢ Membership Inference: Bestimmung, ob bestimmte Datenpunkte im Trainingsdatensatz enthalten waren, was R√ºckschl√ºsse auf Personen oder vertrauliche Informationen erm√∂glicht.\n‚Ä¢ Data Poisoning: Manipulation von Trainingsdaten kann zu kompromittierten Modellen f√ºhren, die falsche oder sch√§dliche Entscheidungen treffen.\n‚Ä¢ Gradient Leakage: In Federated Learning Szenarien k√∂nnen Gradienten-Updates unbeabsichtigt private Informationen √ºber lokale Daten preisgeben.\n\nüõ°Ô∏è ADVISORI's Comprehensive Security Framework:\n‚Ä¢ Privacy-by-Design Integration: Wir implementieren Datenschutzprinzipien bereits in der Architekturphase, nicht als nachtr√§gliche Erg√§nzung.\n‚Ä¢ Multi-Layer Defense: Kombination aus technischen, organisatorischen und rechtlichen Schutzma√ünahmen f√ºr umfassende Sicherheit.\n‚Ä¢ Continuous Monitoring: Etablierung von Systemen zur kontinuierlichen √úberwachung von Modellverhalten und Anomalieerkennung.\n‚Ä¢ Adaptive Security: Entwicklung von Sicherheitsma√ünahmen, die sich an neue Bedrohungen und Angriffsvektoren anpassen k√∂nnen.\n\nüîê Advanced Privacy-Preserving Techniques:\n‚Ä¢ Differential Privacy: Mathematisch garantierte Privatsph√§re durch kontrollierte Rauschzugabe zu Daten oder Modellausgaben.\n‚Ä¢ Homomorphic Encryption: Berechnungen auf verschl√ºsselten Daten ohne Entschl√ºsselung, um Datenschutz w√§hrend der Verarbeitung zu gew√§hrleisten.\n‚Ä¢ Secure Multi-Party Computation: Erm√∂glicht kollaborative KI-Entwicklung ohne Preisgabe sensibler Daten zwischen Parteien.\n‚Ä¢ Federated Learning: Dezentrales Training, bei dem Daten nie die urspr√ºnglichen Standorte verlassen m√ºssen."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 2),
        question: 'Wie implementiert ADVISORI DSGVO-konforme KI-Systeme und welche spezifischen Anforderungen gelten f√ºr die Verarbeitung personenbezogener Daten in Machine Learning?',
        answer: "Die DSGVO-konforme Implementierung von KI-Systemen erfordert eine durchdachte Balance zwischen innovativer Technologie und rigoroser Compliance. ADVISORI entwickelt KI-L√∂sungen, die nicht nur den Buchstaben, sondern auch den Geist der DSGVO erf√ºllen, indem wir Privacy-by-Design-Prinzipien von Anfang an integrieren und transparente, nachvollziehbare Datenverarbeitungsprozesse schaffen.\n\nüìã DSGVO-Kernprinzipien in KI-Implementierung:\n‚Ä¢ Rechtm√§√üigkeit und Transparenz: Klare Rechtsgrundlagen f√ºr jede Datenverarbeitung und verst√§ndliche Erkl√§rungen der KI-Entscheidungsprozesse f√ºr Betroffene.\n‚Ä¢ Zweckbindung: Sicherstellung, dass KI-Systeme nur f√ºr die urspr√ºnglich definierten und kommunizierten Zwecke verwendet werden.\n‚Ä¢ Datenminimierung: Verwendung nur der minimal notwendigen Daten f√ºr effektive KI-Funktionalit√§t ohne √úbersammlung.\n‚Ä¢ Richtigkeit: Implementierung von Mechanismen zur Gew√§hrleistung der Datenqualit√§t und -aktualit√§t in ML-Pipelines.\n‚Ä¢ Speicherbegrenzung: Automatisierte L√∂schung von Daten nach Ablauf der Aufbewahrungsfristen.\n\nüîí Technische DSGVO-Compliance-Ma√ünahmen:\n‚Ä¢ Privacy-by-Design Architecture: Entwicklung von KI-Systemen mit eingebauten Datenschutzfunktionen, die standardm√§√üig aktiviert sind.\n‚Ä¢ Pseudonymisierung und Anonymisierung: Implementierung robuster Verfahren zur Entfernung oder Verschleierung personenbezogener Identifikatoren.\n‚Ä¢ Consent Management: Entwicklung granularer Einverst√§ndnissysteme, die dynamische Zustimmung f√ºr verschiedene KI-Anwendungen erm√∂glichen.\n‚Ä¢ Right to Explanation: Schaffung interpretierbarer KI-Modelle, die nachvollziehbare Erkl√§rungen f√ºr automatisierte Entscheidungen liefern k√∂nnen.\n‚Ä¢ Data Subject Rights: Technische Implementierung von Betroffenenrechten wie Auskunft, Berichtigung, L√∂schung und Daten√ºbertragbarkeit.\n\n‚öñÔ∏è Rechtliche und Organisatorische Compliance:\n‚Ä¢ Datenschutz-Folgenabsch√§tzung: Systematische Bewertung von Datenschutzrisiken vor der Implementierung neuer KI-Systeme.\n‚Ä¢ Auftragsverarbeitung: Strukturierung von KI-Projekten mit klaren Verantwortlichkeiten zwischen Verantwortlichen und Auftragsverarbeitern.\n‚Ä¢ Internationale Daten√ºbermittlung: Sicherstellung angemessener Schutzma√ünahmen bei grenz√ºberschreitender KI-Datenverarbeitung.\n‚Ä¢ Dokumentation und Audit-Trails: Umfassende Protokollierung aller Datenverarbeitungsaktivit√§ten f√ºr Compliance-Nachweise."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 3),
        question: 'Welche Privacy-by-Design-Prinzipien wendet ADVISORI bei der Entwicklung sicherer KI-Architekturen an und wie werden diese technisch umgesetzt?',
        answer: "Privacy-by-Design ist nicht nur ein Compliance-Ansatz, sondern ein fundamentales Designprinzip, das Datenschutz als integralen Bestandteil der KI-Architektur verankert. ADVISORI implementiert diese Prinzipien durch eine Kombination aus technischen Innovationen, architektonischen Entscheidungen und organisatorischen Prozessen, die Datenschutz zur Standardfunktion machen, nicht zur nachtr√§glichen Erg√§nzung.\n\nüèóÔ∏è Architektonische Privacy-by-Design-Umsetzung:\n‚Ä¢ Data Minimization by Design: KI-Systeme werden so entwickelt, dass sie nur die minimal notwendigen Daten sammeln und verarbeiten, mit automatischen Mechanismen zur Identifikation und Eliminierung redundanter Informationen.\n‚Ä¢ Decentralized Processing: Implementierung von Edge-Computing und Federated Learning Ans√§tzen, die Datenverarbeitung n√§her zur Quelle bringen und zentrale Datenspeicherung minimieren.\n‚Ä¢ Modular Security Architecture: Entwicklung modularer Systeme mit isolierten Komponenten, die unabh√§ngige Sicherheitskontrollen und granulare Zugriffsbeschr√§nkungen erm√∂glichen.\n‚Ä¢ Automated Privacy Controls: Integration automatisierter Systeme zur kontinuierlichen √úberwachung und Durchsetzung von Datenschutzrichtlinien ohne manuellen Eingriff.\n\nüîê Technische Privacy-Preserving-Implementierung:\n‚Ä¢ Differential Privacy Integration: Systematische Anwendung von Differential Privacy Techniken in allen Phasen des ML-Lebenszyklus, von der Datensammlung bis zur Modellausgabe.\n‚Ä¢ Homomorphic Encryption Deployment: Implementierung von Verschl√ºsselungsverfahren, die Berechnungen auf verschl√ºsselten Daten erm√∂glichen, ohne diese jemals zu entschl√ºsseln.\n‚Ä¢ Secure Aggregation: Entwicklung von Protokollen f√ºr sichere Aggregation von Daten aus mehreren Quellen ohne Preisgabe individueller Beitr√§ge.\n‚Ä¢ Zero-Knowledge Proofs: Anwendung kryptographischer Verfahren, die die Richtigkeit von Berechnungen beweisen k√∂nnen, ohne die zugrundeliegenden Daten preiszugeben.\n\nüõ°Ô∏è Proactive Privacy Protection:\n‚Ä¢ Privacy Impact Assessment Automation: Entwicklung automatisierter Tools zur kontinuierlichen Bewertung von Datenschutzauswirkungen w√§hrend der Systementwicklung.\n‚Ä¢ Dynamic Consent Management: Implementierung flexibler Einverst√§ndnissysteme, die sich an ver√§nderte Nutzungsszenarien anpassen k√∂nnen.\n‚Ä¢ Privacy-Preserving Analytics: Entwicklung von Analyseverfahren, die wertvolle Erkenntnisse liefern, ohne individuelle Privatsph√§re zu kompromittieren.\n‚Ä¢ Continuous Privacy Monitoring: Etablierung von Systemen zur kontinuierlichen √úberwachung der Datenschutz-Performance und automatischen Anpassung bei Abweichungen."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 4),
        question: 'Wie sch√ºtzt ADVISORI vor Data Poisoning und Adversarial Attacks in KI-Systemen und welche pr√§ventiven Sicherheitsma√ünahmen werden implementiert?',
        answer: "Data Poisoning und Adversarial Attacks stellen ernsthafte Bedrohungen f√ºr die Integrit√§t und Sicherheit von KI-Systemen dar. Diese Angriffe k√∂nnen nicht nur die Funktionalit√§t von Modellen beeintr√§chtigen, sondern auch zu Datenschutzverletzungen und Sicherheitsl√ºcken f√ºhren. ADVISORI entwickelt mehrschichtige Verteidigungsstrategien, die sowohl pr√§ventive als auch reaktive Ma√ünahmen umfassen, um die Robustheit und Sicherheit von KI-Systemen zu gew√§hrleisten.\n\nüõ°Ô∏è Multi-Layer Defense Against Data Poisoning:\n‚Ä¢ Input Validation and Sanitization: Implementierung robuster Datenvalidierungssysteme, die anomale oder verd√§chtige Datenpunkte vor der Integration in Trainingsdatens√§tze identifizieren und isolieren.\n‚Ä¢ Statistical Anomaly Detection: Entwicklung fortschrittlicher statistischer Verfahren zur Erkennung von Datenmustern, die auf Manipulation oder Poisoning hindeuten k√∂nnten.\n‚Ä¢ Federated Learning Security: Spezielle Schutzma√ünahmen f√ºr dezentrale Lernszenarien, einschlie√ülich Byzantine-fault-toleranter Aggregationsverfahren und Reputation-basierter Teilnehmervalidierung.\n‚Ä¢ Data Provenance Tracking: Implementierung umfassender Systeme zur Nachverfolgung der Datenherkunft und -integrit√§t durch die gesamte ML-Pipeline.\n\n‚öîÔ∏è Adversarial Attack Mitigation Strategies:\n‚Ä¢ Adversarial Training: Systematische Integration adversarieller Beispiele in den Trainingsprozess, um Modellrobustheit gegen bekannte Angriffsmuster zu erh√∂hen.\n‚Ä¢ Input Preprocessing: Entwicklung spezialisierter Vorverarbeitungstechniken, die adversarielle Perturbationen neutralisieren k√∂nnen, ohne die Datenqualit√§t zu beeintr√§chtigen.\n‚Ä¢ Ensemble Defense: Verwendung mehrerer diverser Modelle mit unterschiedlichen Architekturen und Trainingsdaten, um die Wahrscheinlichkeit erfolgreicher Angriffe zu reduzieren.\n‚Ä¢ Gradient Masking Prevention: Implementierung von Techniken zur Verhinderung von Gradient Masking, das falsche Sicherheit gegen adversarielle Angriffe vort√§uschen kann.\n\nüîç Continuous Security Monitoring:\n‚Ä¢ Real-time Threat Detection: Entwicklung von Systemen zur kontinuierlichen √úberwachung von Modelleingaben und -ausgaben auf Anzeichen adversarieller Aktivit√§ten.\n‚Ä¢ Behavioral Analysis: Implementierung von Verfahren zur Analyse des Modellverhaltens und Erkennung ungew√∂hnlicher Muster, die auf Kompromittierung hindeuten k√∂nnten.\n‚Ä¢ Automated Response Systems: Entwicklung automatisierter Reaktionssysteme, die bei Erkennung von Angriffen sofortige Schutzma√ünahmen einleiten k√∂nnen.\n‚Ä¢ Security Audit Trails: Umfassende Protokollierung aller sicherheitsrelevanten Ereignisse f√ºr forensische Analyse und Compliance-Nachweise."
      }
    ]
    
    // Update the document with new FAQs
    const updatedFaqs = [...(existingDoc.faq || []), ...newFaqs]
    
    console.log(`Adding ${newFaqs.length} new FAQs to the document...`)
    const transaction = client.transaction()
    transaction.patch(existingDoc._id, {
      set: {
        faq: updatedFaqs
      }
    })
    
    await transaction.commit()
    console.log('‚úÖ FAQs batch 1 added successfully')
  } catch (error) {
    console.error('Error:', error)
    throw error
  }
}

run()
