import 'dotenv/config'
import { createClient } from '@sanity/client'

// Create client with direct credentials
const client = createClient({
  projectId: 'wwmm9rbb',
  dataset: 'production',
  apiVersion: '2024-02-14',
  token: process.env.SANITY_API_TOKEN,
  useCdn: false,
})

// Helper function to generate unique keys
function generateKey(prefix: string, index: number): string {
  return `${prefix}_${Date.now()}_${index}`
}

const run = async () => {
  try {
    console.log('Updating DORA Informationsregister page with FAQ batch 3...')
    
    // First, get the existing document
    console.log('Fetching existing document...')
    const existingDoc = await client.fetch('*[_id == $id][0]', { id: 'dora-informationsregister' })
    
    if (!existingDoc) {
      throw new Error('Document "dora-informationsregister" not found')
    }
    
    // Create new FAQs for DORA information register security and compliance
    const newFaqs = [
      {
        _type: 'object',
        _key: generateKey('faq', 9),
        question: 'Wie gew√§hrleiste ich die Sicherheit und den Datenschutz meines DORA-Informationsregisters?',
        answer: "Die Sicherheit und der Datenschutz von DORA-Informationsregistern sind von kritischer Bedeutung, da diese sensible Informationen √ºber die gesamte IKT-Infrastruktur enthalten. Ein Kompromiss des Registers k√∂nnte Angreifern detaillierte Einblicke in Systemarchitekturen und Schwachstellen gew√§hren. Daher erfordern diese Systeme mehrschichtige Sicherheitsma√ünahmen und strikte Datenschutzkontrollen.\n\nüîê Zugriffskontrolle und Identit√§tsmanagement:\n‚Ä¢ Implementierung von Zero-Trust-Prinzipien mit kontinuierlicher Authentifizierung und Autorisierung\n‚Ä¢ Role-based Access Control mit granularen Berechtigungen basierend auf Job-Funktionen und Need-to-Know-Prinzipien\n‚Ä¢ Multi-Factor-Authentication f√ºr alle Benutzer mit privilegierten Zugriff auf das Register\n‚Ä¢ Privileged Access Management f√ºr administrative Funktionen mit Session-Recording und Approval-Workflows\n‚Ä¢ Regular Access Reviews und automatische Deprovisioning bei Rollen√§nderungen oder Mitarbeiterabg√§ngen\n\nüõ°Ô∏è Datenverschl√ºsselung und Schutz sensibler Informationen:\n‚Ä¢ End-to-End-Verschl√ºsselung f√ºr alle Daten√ºbertragungen mit modernen Verschl√ºsselungsstandards\n‚Ä¢ Encryption-at-Rest f√ºr alle gespeicherten Register-Daten mit Hardware Security Modules f√ºr Schl√ºsselverwaltung\n‚Ä¢ Data Classification und Labeling f√ºr unterschiedliche Schutzlevel verschiedener Informationskategorien\n‚Ä¢ Tokenization oder Pseudonymisierung f√ºr besonders sensible Daten wie Konfigurationsdetails\n‚Ä¢ Secure Key Management mit regelm√§√üiger Schl√ºsselrotation und Escrow-Verfahren\n\nüîç Monitoring und Anomalie-Erkennung:\n‚Ä¢ Security Information and Event Management f√ºr kontinuierliche √úberwachung aller Register-Aktivit√§ten\n‚Ä¢ User and Entity Behavior Analytics f√ºr Erkennung ungew√∂hnlicher Zugriffsmuster\n‚Ä¢ Data Loss Prevention f√ºr Schutz vor unautorisierten Datenexporten oder -√ºbertragungen\n‚Ä¢ Real-Time-Alerting bei verd√§chtigen Aktivit√§ten oder Sicherheitsverletzungen\n‚Ä¢ Forensic-Capabilities f√ºr detaillierte Untersuchung von Sicherheitsvorf√§llen\n\nüìã Compliance und regulatorische Anforderungen:\n‚Ä¢ GDPR-Compliance f√ºr Verarbeitung personenbezogener Daten in Register-Kontexten\n‚Ä¢ Data Retention Policies mit automatischer Archivierung und L√∂schung nach definierten Zeitr√§umen\n‚Ä¢ Privacy-by-Design-Prinzipien bei der Entwicklung und Erweiterung des Registers\n‚Ä¢ Regular Privacy Impact Assessments f√ºr neue Features oder Datenquellen\n‚Ä¢ Audit-Trail-Completeness f√ºr Nachweisf√ºhrung bei regulatorischen Pr√ºfungen\n\nüèóÔ∏è Infrastruktursicherheit und Resilienz:\n‚Ä¢ Secure-by-Design-Architektur mit Defense-in-Depth-Strategien\n‚Ä¢ Network Segmentation und Micro-Segmentation f√ºr Isolation kritischer Register-Komponenten\n‚Ä¢ Regular Vulnerability Assessments und Penetration Testing\n‚Ä¢ Backup und Disaster Recovery mit verschl√ºsselten Off-Site-Backups\n‚Ä¢ Business Continuity Planning f√ºr Aufrechterhaltung der Register-Verf√ºgbarkeit bei Sicherheitsvorf√§llen"
      },
      {
        _type: 'object',
        _key: generateKey('faq', 10),
        question: 'Welche Best Practices gibt es f√ºr die Schulung und das Change Management bei der Einf√ºhrung von DORA-Informationsregistern?',
        answer: "Die erfolgreiche Einf√ºhrung von DORA-Informationsregistern h√§ngt ma√ügeblich von effektivem Change Management und umfassender Mitarbeiterschulung ab. Widerstand gegen Ver√§nderungen und mangelnde Akzeptanz k√∂nnen selbst die beste technische L√∂sung zum Scheitern bringen. Ein strukturierter Ansatz zur Organisationsentwicklung ist daher entscheidend f√ºr nachhaltigen Erfolg.\n\nüë• Stakeholder-Engagement und Kommunikationsstrategie:\n‚Ä¢ Fr√ºhe Einbindung aller relevanten Stakeholder in die Planungs- und Designphase des Registers\n‚Ä¢ Entwicklung einer umfassenden Kommunikationsstrategie mit klaren Botschaften √ºber Nutzen und Notwendigkeit\n‚Ä¢ Regular Town Halls und Update-Sessions f√ºr kontinuierliche Transparenz √ºber Projektfortschritt\n‚Ä¢ Champion-Netzwerk mit einflussreichen Mitarbeitern als Multiplikatoren und Change Agents\n‚Ä¢ Feedback-Mechanismen f√ºr kontinuierliche Verbesserung basierend auf Nutzererfahrungen\n\nüìö Strukturierte Schulungsprogramme und Kompetenzentwicklung:\n‚Ä¢ Role-based Training Programs mit spezifischen Inhalten f√ºr verschiedene Nutzergruppen\n‚Ä¢ Hands-on Workshops und Simulation-Exercises f√ºr praktische Erfahrung mit dem Register\n‚Ä¢ E-Learning-Plattformen f√ºr flexible und skalierbare Schulungsdelivery\n‚Ä¢ Mentoring-Programme mit erfahrenen Nutzern als Unterst√ºtzung f√ºr neue Anwender\n‚Ä¢ Continuous Learning Paths f√ºr fortlaufende Kompetenzentwicklung und System-Updates\n\nüîÑ Phasenweise Einf√ºhrung und Pilotprogramme:\n‚Ä¢ Pilot-Implementierung mit ausgew√§hlten Bereichen f√ºr Lessons Learned und Optimierung\n‚Ä¢ Phased Rollout mit schrittweiser Erweiterung auf weitere Organisationsbereiche\n‚Ä¢ Quick Wins und Early Success Stories f√ºr Momentum-Building und Akzeptanzsteigerung\n‚Ä¢ Iterative Verbesserung basierend auf Pilot-Feedback und Performance-Metriken\n‚Ä¢ Risk Mitigation durch kontrollierte Einf√ºhrung und Fallback-Strategien\n\nüìä Performance-Monitoring und Adoption-Tracking:\n‚Ä¢ User Adoption Metrics f√ºr √úberwachung der Nutzungsraten und Engagement-Level\n‚Ä¢ Quality Metrics f√ºr Bewertung der Datenqualit√§t und Vollst√§ndigkeit\n‚Ä¢ Satisfaction Surveys f√ºr kontinuierliches Feedback zur Nutzererfahrung\n‚Ä¢ Performance Dashboards f√ºr Transparenz √ºber Erfolg und Verbesserungsbereiche\n‚Ä¢ Regular Reviews und Anpassungen der Change-Management-Strategie\n\nüéØ Kulturwandel und nachhaltige Verankerung:\n‚Ä¢ Integration der Register-Nutzung in bestehende Arbeitsprozesse und Performance-Bewertungen\n‚Ä¢ Recognition und Incentive Programs f√ºr aktive Nutzer und Datenqualit√§ts-Champions\n‚Ä¢ Governance-Integration mit klaren Rollen und Verantwortlichkeiten f√ºr Register-Maintenance\n‚Ä¢ Continuous Improvement Culture mit regelm√§√üigen Retrospektiven und Optimierungszyklen\n‚Ä¢ Knowledge Management f√ºr Dokumentation von Best Practices und Lessons Learned"
      },
      {
        _type: 'object',
        _key: generateKey('faq', 11),
        question: 'Wie plane ich die Migration von bestehenden Asset-Inventaren zu einem DORA-konformen Informationsregister?',
        answer: "Die Migration bestehender Asset-Inventare zu einem DORA-konformen Informationsregister ist ein komplexer Transformationsprozess, der sorgf√§ltige Planung, Datenbereinigung und schrittweise Umsetzung erfordert. Legacy-Systeme enthalten oft unvollst√§ndige oder inkonsistente Daten, die vor der Migration harmonisiert und angereichert werden m√ºssen.\n\nüîç Assessment und Bestandsaufnahme bestehender Systeme:\n‚Ä¢ Comprehensive Inventory aller bestehenden Asset-Management-Systeme und Datenquellen\n‚Ä¢ Data Quality Assessment f√ºr Bewertung der Vollst√§ndigkeit, Genauigkeit und Konsistenz vorhandener Daten\n‚Ä¢ Gap Analysis zwischen aktuellen Datenstrukturen und DORA-Anforderungen\n‚Ä¢ Dependency Mapping f√ºr Verst√§ndnis der Beziehungen zwischen verschiedenen Systemen\n‚Ä¢ Stakeholder Analysis f√ºr Identifikation aller betroffenen Teams und Prozesse\n\nüìä Datenbereinigung und Harmonisierung:\n‚Ä¢ Data Profiling f√ºr detaillierte Analyse der Datenqualit√§t und Identifikation von Problemen\n‚Ä¢ Deduplication und Consolidation von redundanten oder widerspr√ºchlichen Eintr√§gen\n‚Ä¢ Standardization von Naming Conventions und Klassifizierungsschemata\n‚Ä¢ Data Enrichment durch Anreicherung fehlender Informationen aus zus√§tzlichen Quellen\n‚Ä¢ Validation Rules f√ºr Sicherstellung der Datenqualit√§t w√§hrend der Migration\n\nüõ†Ô∏è Technische Migrations-Architektur:\n‚Ä¢ ETL-Pipeline-Design f√ºr systematische Datenextraktion, Transformation und Loading\n‚Ä¢ Staging-Environment f√ºr sichere Datenverarbeitung und Testing vor Produktions-Migration\n‚Ä¢ Data Mapping zwischen Legacy-Formaten und neuen DORA-konformen Strukturen\n‚Ä¢ Error Handling und Rollback-Mechanismen f√ºr Behandlung von Migrations-Problemen\n‚Ä¢ Performance Optimization f√ºr effiziente Verarbeitung gro√üer Datenmengen\n\nüìÖ Phasenweise Migrations-Strategie:\n‚Ä¢ Pilot Migration mit nicht-kritischen Assets f√ºr Testing und Optimierung der Prozesse\n‚Ä¢ Priority-based Rollout beginnend mit den gesch√§ftskritischsten Assets\n‚Ä¢ Parallel Running von Legacy- und neuen Systemen w√§hrend der √úbergangsphase\n‚Ä¢ Incremental Migration mit regelm√§√üigen Checkpoints und Validierung\n‚Ä¢ Final Cutover mit koordinierter Abschaltung der Legacy-Systeme\n\nüîÑ Qualit√§tssicherung und Validierung:\n‚Ä¢ Automated Testing f√ºr Verifikation der Datenintegrit√§t nach Migration\n‚Ä¢ User Acceptance Testing mit Fachexperten f√ºr Validierung der Gesch√§ftslogik\n‚Ä¢ Reconciliation Processes f√ºr Abgleich zwischen Legacy- und neuen Daten\n‚Ä¢ Performance Testing f√ºr Sicherstellung der System-Performance unter Last\n‚Ä¢ Security Testing f√ºr Verifikation der Sicherheitskontrollen im neuen System"
      },
      {
        _type: 'object',
        _key: generateKey('faq', 12),
        question: 'Welche Rolle spielt das Informationsregister bei der DORA-Berichterstattung an Aufsichtsbeh√∂rden?',
        answer: "Das DORA-Informationsregister bildet das Fundament f√ºr alle aufsichtsrechtlichen Berichtspflichten und erm√∂glicht zeitnahe, vollst√§ndige und genaue Kommunikation mit Regulatoren. Die Qualit√§t und Vollst√§ndigkeit des Registers bestimmt direkt die F√§higkeit einer Organisation, regulatorische Anfragen zu beantworten und Compliance nachzuweisen.\n\nüìã Regulatorische Berichtspflichten und Anforderungen:\n‚Ä¢ Incident Reporting mit detaillierten Informationen √ºber betroffene Systeme und deren Gesch√§ftsauswirkungen\n‚Ä¢ Periodic Risk Assessments basierend auf aktuellen Asset-Inventaren und Risikobewertungen\n‚Ä¢ Third-Party Risk Reporting mit umfassender Dokumentation aller kritischen IKT-Drittanbieter\n‚Ä¢ Operational Resilience Metrics mit quantitativen Daten √ºber System-Performance und Verf√ºgbarkeit\n‚Ä¢ Change Notifications f√ºr wesentliche √Ñnderungen in der IKT-Landschaft oder Risikoprofil\n\nüîÑ Automatisierte Berichtsgenerierung und Datenextraktion:\n‚Ä¢ Template-based Reporting mit vorkonfigurierten Formaten f√ºr verschiedene regulatorische Anforderungen\n‚Ä¢ Real-Time Data Extraction f√ºr zeitnahe Bereitstellung aktueller Informationen\n‚Ä¢ Automated Quality Checks f√ºr Sicherstellung der Vollst√§ndigkeit und Genauigkeit vor √úbermittlung\n‚Ä¢ Version Control und Audit Trails f√ºr Nachverfolgbarkeit aller √ºbermittelten Berichte\n‚Ä¢ Multi-Format Export f√ºr verschiedene √úbermittlungskan√§le und Regulatoren-Pr√§ferenzen\n\nüìä Datenqualit√§t und Compliance-Readiness:\n‚Ä¢ Continuous Validation gegen regulatorische Taxonomien und Standards\n‚Ä¢ Completeness Monitoring f√ºr Sicherstellung vollst√§ndiger Datenerfassung\n‚Ä¢ Accuracy Verification durch Cross-Reference mit authoritative Quellen\n‚Ä¢ Timeliness Tracking f√ºr rechtzeitige Aktualisierung kritischer Informationen\n‚Ä¢ Consistency Checks f√ºr einheitliche Darstellung √ºber verschiedene Berichte hinweg\n\nüéØ Proaktive Compliance-√úberwachung:\n‚Ä¢ Regulatory Change Monitoring f√ºr fr√ºhzeitige Anpassung an neue Anforderungen\n‚Ä¢ Gap Analysis f√ºr Identifikation fehlender Informationen vor Berichtspflichten\n‚Ä¢ Scenario Planning f√ºr Vorbereitung auf verschiedene Reporting-Anforderungen\n‚Ä¢ Stress Testing der Berichtsf√§higkeiten unter verschiedenen Belastungsszenarien\n‚Ä¢ Continuous Improvement basierend auf Regulator-Feedback und Industry Best Practices\n\nüîç Aufsichtspr√ºfungen und Dokumentation:\n‚Ä¢ Comprehensive Documentation aller Register-Prozesse und Datenquellen f√ºr Pr√ºfer\n‚Ä¢ Evidence Management f√ºr strukturierte Bereitstellung von Nachweisen\n‚Ä¢ Query Response Capabilities f√ºr schnelle Beantwortung spezifischer Aufsichtsfragen\n‚Ä¢ Historical Data Preservation f√ºr langfristige Nachverfolgbarkeit und Trend-Analysen\n‚Ä¢ Stakeholder Communication f√ºr koordinierte Interaktion mit verschiedenen Aufsichtsbeh√∂rden"
      }
    ]
    
    // Update the document with new FAQs
    const updatedFaqs = [...(existingDoc.faq || []), ...newFaqs]
    
    console.log(`Adding ${newFaqs.length} new FAQs to the document...`)
    const transaction = client.transaction()
    transaction.patch(existingDoc._id, {
      set: {
        faq: updatedFaqs
      }
    })
    
    await transaction.commit()
    console.log('‚úÖ FAQ batch 3 added successfully')
  } catch (error) {
    console.error('Error:', error)
    throw error
  }
}

run()
