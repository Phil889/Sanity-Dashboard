import 'dotenv/config'
import { createClient } from '@sanity/client'

// Create client with direct credentials
const client = createClient({
  projectId: 'wwmm9rbb',
  dataset: 'production',
  apiVersion: '2024-02-14',
  token: process.env.SANITY_API_TOKEN,
  useCdn: false,
})

// Helper function to generate unique keys
function generateKey(prefix: string, index: number): string {
  return `${prefix}_${Date.now()}_${index}`
}

const run = async () => {
  try {
    console.log('Updating EU AI Act Risk Assessment page with C-Level FAQs batch 2 (German)...')
    
    // First, get the existing document
    console.log('Fetching existing document...')
    const existingDoc = await client.fetch('*[_id == $id][0]', { id: 'eu-ai-act-risk-assessment' })
    
    if (!existingDoc) {
      throw new Error('Document "eu-ai-act-risk-assessment" not found')
    }
    
    // Create new C-Level FAQs in German
    const newFaqs = [
      {
        _type: 'object',
        _key: generateKey('faq', 5),
        question: "Wie gew√§hrleistet ADVISORI, dass unser AI Risk Assessment Framework sektorspezifische Anforderungen und branchenspezifische Risiken ad√§quat abbildet?",
        answer: "Verschiedene Branchen und Sektoren weisen fundamental unterschiedliche AI-Risikoprofile auf, die eine standardisierte Bewertung unzureichend machen. ADVISORI entwickelt ma√ügeschneiderte Risk Assessment Frameworks, die sowohl EU AI Act Compliance als auch branchenspezifische Regulierung und Risikokomplexit√§t optimal adressieren.\n\nüè¶ Sektor-spezifische Risk Assessment Expertise:\n‚Ä¢ Financial Services: Integration von Prudential Regulation, DORA, MiFID II und anderen Banking-spezifischen Anforderungen in AI Risk Assessment Prozesse, mit besonderem Fokus auf Algorithmic Trading und Credit Decision Making.\n‚Ä¢ Healthcare und Life Sciences: Ber√ºcksichtigung von Medical Device Regulation (MDR), GDPR Health Data Provisions und klinischer Validierungsanforderungen bei AI-gest√ºtzten Diagnose- und Behandlungssystemen.\n‚Ä¢ Automotive und Manufacturing: Integration von ISO 26262 (Functional Safety), UNECE Regulations und Industry 4.0 Standards in AI Risk Assessment f√ºr autonome Systeme und predictive Maintenance.\n‚Ä¢ Energy und Utilities: Compliance mit kritischer Infrastruktur-Regulierung, NIS2 Directive und Grid Code Requirements f√ºr AI-gest√ºtzte Smart Grid und Energy Management Systeme.\n\nüéØ Branchen-optimierte Methodologien:\n‚Ä¢ Risk Context Mapping: Entwicklung branchenspezifischer Risk Context Maps, die regulatorische, technische und Gesch√§ftsrisiken in Relation zu AI Use Cases setzen.\n‚Ä¢ Stakeholder Impact Analysis: Systematische Bewertung der Auswirkungen von AI-Systemen auf branchenspezifische Stakeholder (Patienten, Anleger, Verbraucher, Mitarbeiter).\n‚Ä¢ Regulatory Convergence Planning: Koordination zwischen EU AI Act Requirements und bestehenden sektorspezifischen Regulations f√ºr koh√§rente Compliance-Strategien.\n‚Ä¢ Industry Best Practice Integration: Einbindung branchenf√ºhrender Risk Management Praktiken und Standards in ma√ügeschneiderte Assessment Frameworks."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 6),
        question: "Welche Rolle spielt AI Risk Assessment bei der Optimierung unserer ESG-Performance und wie tr√§gt dies zur nachhaltigen Unternehmensf√ºhrung bei?",
        answer: "AI Risk Assessment entwickelt sich zunehmend zu einem kritischen ESG-Faktor, der direkt auf Environmental, Social und Governance Performance einzahlt. F√ºr die C-Suite bedeutet dies, dass systematisches AI Risk Management nicht nur regulatorische Compliance sicherstellt, sondern auch ESG-Ratings verbessert und Zugang zu nachhaltigkeitsorientierten Investoren und Kunden schafft.\n\nüå± ESG-Integration durch AI Risk Excellence:\n‚Ä¢ Environmental Impact: Systematische Bewertung des Energieverbrauchs und CO2-Footprints von AI-Systemen, mit Optimierungsstrategien f√ºr Green AI und nachhaltige Computing-Praktiken.\n‚Ä¢ Social Responsibility: Comprehensive Assessment von AI Bias, Fairness und Inclusive Design, um sicherzustellen, dass AI-Systeme positive gesellschaftliche Auswirkungen haben und keine diskriminierenden Effekte erzeugen.\n‚Ä¢ Governance Excellence: Implementation transparenter AI Governance Strukturen mit klaren Accountability Mechanisms und ethischen Leitlinien, die institutional investor Standards erf√ºllen.\n‚Ä¢ Stakeholder Transparency: Entwicklung von Public Reporting Frameworks f√ºr AI Risk Management, die Transparency und Trust bei externen Stakeholdern schaffen.\n\nüìä ESG Value Creation durch Risk Management:\n‚Ä¢ Sustainable Finance Enablement: AI Risk Assessment Dokumentation erf√ºllt EU Taxonomy Requirements und erm√∂glicht Zugang zu Green Bonds und ESG-linked Financing mit g√ºnstigeren Konditionen.\n‚Ä¢ Rating Agency Recognition: Professionelle AI Risk Management Praktiken werden zunehmend von ESG Rating Agencies (MSCI, Sustainalytics, ISS) als positive Faktoren bewertet.\n‚Ä¢ Customer Trust und Brand Value: Transparente AI Risk Assessment st√§rkt Brand Reputation und erm√∂glicht Premium-Positionierung bei nachhaltigkeitsorientierten Kunden.\n‚Ä¢ Talent Attraction und Retention: Moderne Professionals pr√§ferieren Arbeitgeber mit ethischen AI-Praktiken, was Recruitment-Kosten reduziert und Employee Engagement erh√∂ht."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 7),
        question: "Wie integriert ADVISORI AI Risk Assessment in bestehende Enterprise Risk Management Systeme ohne organisatorische Disruption?",
        answer: "Die nahtlose Integration von AI Risk Assessment in etablierte ERM-Frameworks ist entscheidend f√ºr C-Level Akzeptanz und operative Effizienz. ADVISORI verfolgt einen integrativen Ansatz, der bestehende Risk Management Infrastrukturen nutzt und erweitert, anstatt parallele Systeme zu schaffen, die zu Fragmentierung und Ineffizienz f√ºhren w√ºrden.\n\nüîó Seamless ERM Integration Strategy:\n‚Ä¢ Risk Taxonomy Harmonization: Alignment von AI-spezifischen Risikokategorien mit bestehenden Enterprise Risk Taxonomies, um konsistente Reporting und Management Strukturen zu gew√§hrleisten.\n‚Ä¢ Governance Structure Integration: Einbindung von AI Risk Assessment in bestehende Risk Committee Strukturen und Board Reporting Frameworks ohne zus√§tzliche Governance-Komplexit√§t.\n‚Ä¢ System Architecture Compatibility: Design von AI Risk Assessment Tools und Dashboards, die mit bestehenden GRC Platforms und Risk Management Systemen interoperabel sind.\n‚Ä¢ Process Optimization: Entwicklung von AI Risk Assessment Workflows, die bestehende Risk Review Zyklen und Reporting Deadlines respektieren und optimieren.\n\n‚öôÔ∏è Operational Excellence durch Integration:\n‚Ä¢ Three Lines of Defense Alignment: Klare Zuordnung von AI Risk Assessment Responsibilities zu First, Second und Third Line Functions entsprechend etablierter Risk Management Strukturen.\n‚Ä¢ Risk Appetite Integration: Entwicklung von AI-spezifischen Risk Appetite Statements, die konsistent mit √ºbergeordneten Enterprise Risk Tolerance Levels sind.\n‚Ä¢ Incident Management Convergence: Integration von AI Risk Incidents in bestehende Operational Risk Event Management Systeme f√ºr holistische Risk Response Capabilities.\n‚Ä¢ Training und Change Management: Structured Change Management Programme, die bestehende Risk Management Teams in AI Risk Assessment Methodologien schulen, ohne operative Kontinuit√§t zu gef√§hrden."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 8),
        question: "Wie erm√∂glicht ein robustes AI Risk Assessment Framework die sichere Skalierung von AI-Innovationen ohne Kompromisse bei Geschwindigkeit oder Compliance?",
        answer: "Die zentrale Herausforderung f√ºr innovative Unternehmen liegt in der Balance zwischen AI Innovation Velocity und Risk Management Rigor. ADVISORI's AI Risk Assessment Framework ist darauf ausgelegt, als Innovation Accelerator zu fungieren, indem es predictable Risk Pathways und streamlined Approval Processes schafft, die Geschwindigkeit erh√∂hen, anstatt sie zu bremsen.\n\nüöÄ Innovation Acceleration durch Risk Intelligence:\n‚Ä¢ Pre-approved Risk Templates: Entwicklung von standardisierten Risk Assessment Templates f√ºr h√§ufige AI Use Cases, die Fast-Track Approval Processes f√ºr √§hnliche Anwendungen erm√∂glichen.\n‚Ä¢ Risk-based Scaling Matrices: Creation von Risk-Score-basierten Skalierungsmatrizen, die automatische Freigaben f√ºr Low-Risk AI Deployments und expedited Reviews f√ºr Medium-Risk Applications erm√∂glichen.\n‚Ä¢ Continuous Risk Monitoring: Implementation von Real-Time Risk Monitoring Systemen, die kontinuierliche Performance-√úberwachung erm√∂glichen und Post-Deployment Risk Management automatisieren.\n‚Ä¢ Innovation Sandbox Environments: Etablierung kontrollierter Testing-Umgebungen mit relaxed Risk Requirements f√ºr Proof-of-Concept und Pilot-Deployments.\n\nüí° Strategic Innovation Enablement:\n‚Ä¢ Portfolio Risk Optimization: Holistische Betrachtung des AI Portfolio Risk Profiles, um Strategic Risk Budget Allocation f√ºr High-Value Innovation Opportunities zu optimieren.\n‚Ä¢ Competitive Intelligence Integration: Einbindung von Competitive Risk Analysis in Innovation Planning, um First-Mover Advantages bei neuen AI Applications zu sichern.\n‚Ä¢ Technology Roadmap Alignment: Integration von Risk Assessment Insights in Technology Roadmap Planning f√ºr proaktive Risk Mitigation in der Entwicklungsphase.\n‚Ä¢ Cross-functional Innovation Teams: Aufbau integrierter Innovation Teams mit eingebetteten Risk Assessment Capabilities f√ºr Rapid Innovation Cycles ohne Compliance-Verz√∂gerungen."
      }
    ]
    
    // Update the document with new FAQs
    const updatedFaqs = [...(existingDoc.faq || []), ...newFaqs]
    
    console.log(`Adding ${newFaqs.length} new C-Level FAQs (German) to the document...`)
    const transaction = client.transaction()
    transaction.patch(existingDoc._id, {
      set: {
        faq: updatedFaqs
      }
    })
    
    await transaction.commit()
    console.log('‚úÖ C-Level FAQs batch 2 (German) added successfully')
  } catch (error) {
    console.error('Error:', error)
    throw error
  }
}

run()
