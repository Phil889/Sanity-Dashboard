import 'dotenv/config'
import { createClient } from '@sanity/client'

// Create client with direct credentials
const client = createClient({
  projectId: 'wwmm9rbb',
  dataset: 'production',
  apiVersion: '2024-02-14',
  token: process.env.SANITY_API_TOKEN,
  useCdn: false,
})

// Helper function to generate unique keys
function generateKey(prefix: string, index: number): string {
  return `${prefix}_${Date.now()}_${index}`
}

const run = async () => {
  try {
    console.log('Updating Datensicherheit f√ºr KI page with FAQs batch 2...')
    
    // First, get the existing document
    console.log('Fetching existing document...')
    const existingDoc = await client.fetch('*[_id == $id][0]', { id: 'datensicherheit-fuer-ki' })
    
    if (!existingDoc) {
      throw new Error('Document "datensicherheit-fuer-ki" not found')
    }
    
    // Create new FAQs
    const newFaqs = [
      {
        _type: 'object',
        _key: generateKey('faq', 5),
        question: 'Wie implementiert ADVISORI sichere ML-Pipelines mit End-to-End-Verschl√ºsselung und welche Verschl√ºsselungstechnologien kommen zum Einsatz?',
        answer: "Sichere ML-Pipelines mit End-to-End-Verschl√ºsselung sind essentiell f√ºr den Schutz sensibler Daten w√§hrend des gesamten Machine Learning Lebenszyklus. ADVISORI entwickelt umfassende Verschl√ºsselungsstrategien, die Daten von der Sammlung √ºber die Verarbeitung bis zur Speicherung und √úbertragung sch√ºtzen, ohne dabei die Funktionalit√§t oder Performance der KI-Systeme zu beeintr√§chtigen.\n\nüîê End-to-End-Verschl√ºsselungsarchitektur:\n‚Ä¢ Data-at-Rest Encryption: Implementierung fortschrittlicher Verschl√ºsselungsverfahren f√ºr gespeicherte Daten, einschlie√ülich Trainingsdatens√§tze, Modellparameter und Zwischenergebnisse mit Hardware-Security-Modulen f√ºr Schl√ºsselmanagement.\n‚Ä¢ Data-in-Transit Protection: Sichere √úbertragung aller Daten zwischen verschiedenen Komponenten der ML-Pipeline durch TLS-Verschl√ºsselung und zus√§tzliche Anwendungsschicht-Sicherheit.\n‚Ä¢ Data-in-Use Security: Schutz von Daten w√§hrend der aktiven Verarbeitung durch Technologien wie Intel SGX, AMD Memory Guard und andere Trusted Execution Environments.\n‚Ä¢ Key Management Infrastructure: Entwicklung robuster Schl√ºsselverwaltungssysteme mit automatischer Rotation, Escrow-Verfahren und Multi-Party-Kontrolle f√ºr kritische Verschl√ºsselungsschl√ºssel.\n\nüõ°Ô∏è Advanced Encryption Technologies:\n‚Ä¢ Homomorphic Encryption Implementation: Erm√∂glicht Berechnungen auf verschl√ºsselten Daten ohne Entschl√ºsselung, ideal f√ºr Privacy-Preserving Machine Learning und kollaborative Datenanalyse.\n‚Ä¢ Functional Encryption: Selektive Entschl√ºsselung spezifischer Datenattribute basierend auf Zugriffsrichtlinien, ohne vollst√§ndige Datenpreisgabe.\n‚Ä¢ Searchable Encryption: Erm√∂glicht Suche und Indexierung verschl√ºsselter Daten ohne Kompromittierung der Vertraulichkeit.\n‚Ä¢ Multi-Party Computation: Sichere gemeinsame Berechnungen zwischen mehreren Parteien ohne Preisgabe individueller Datenbeitr√§ge.\n\nüîß Pipeline Security Implementation:\n‚Ä¢ Secure Containerization: Verwendung verschl√ºsselter Container mit Hardware-basierter Attestierung f√ºr isolierte und sichere ML-Workload-Ausf√ºhrung.\n‚Ä¢ Encrypted Model Storage: Schutz trainierter Modelle durch Verschl√ºsselung mit rollenbasiertem Zugriff und Versionskontrolle.\n‚Ä¢ Secure Communication Protocols: Implementierung ma√ügeschneiderter Kommunikationsprotokolle f√ºr sichere Daten√ºbertragung zwischen ML-Pipeline-Komponenten.\n‚Ä¢ Audit Trail Encryption: Verschl√ºsselte Protokollierung aller Pipeline-Aktivit√§ten f√ºr Compliance und forensische Analyse ohne Kompromittierung der Vertraulichkeit."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 6),
        question: 'Welche Rolle spielt Federated Learning in ADVISORI\'s Datensicherheitsstrategie und wie werden dabei Datenschutz und Modellqualit√§t balanciert?',
        answer: "Federated Learning repr√§sentiert einen paradigmatischen Wandel in der KI-Entwicklung, der Datenschutz und Modellqualit√§t in einer bisher unerreichten Weise vereint. ADVISORI nutzt Federated Learning als Kernkomponente unserer Datensicherheitsstrategie, um Organisationen zu erm√∂glichen, von kollaborativer KI zu profitieren, ohne dabei sensible Daten preiszugeben oder Compliance-Anforderungen zu verletzen.\n\nüåê Federated Learning Architecture Excellence:\n‚Ä¢ Decentralized Model Training: Entwicklung von Systemen, die es erm√∂glichen, hochwertige KI-Modelle zu trainieren, ohne dass Rohdaten jemals zentrale Server verlassen oder zwischen Organisationen ausgetauscht werden.\n‚Ä¢ Privacy-Preserving Aggregation: Implementierung fortschrittlicher Aggregationsverfahren, die Modell-Updates kombinieren, ohne individuelle Beitr√§ge oder lokale Datencharakteristika preiszugeben.\n‚Ä¢ Differential Privacy Integration: Systematische Anwendung von Differential Privacy Techniken auf Federated Learning Updates, um mathematisch garantierte Privatsph√§re zu gew√§hrleisten.\n‚Ä¢ Secure Multi-Party Computation: Verwendung kryptographischer Protokolle f√ºr sichere Aggregation von Modell-Updates ohne Preisgabe individueller Gradienten oder Parameter.\n\n‚öñÔ∏è Balancing Privacy and Model Quality:\n‚Ä¢ Adaptive Privacy Budgets: Entwicklung dynamischer Privacy-Budget-Management-Systeme, die Datenschutz und Modellperformance optimal ausbalancieren basierend auf spezifischen Anwendungsanforderungen.\n‚Ä¢ Quality-Preserving Noise Addition: Implementierung intelligenter Rauschzugabe-Verfahren, die Privatsph√§re sch√ºtzen, w√§hrend sie minimale Auswirkungen auf Modellgenauigkeit haben.\n‚Ä¢ Selective Participation: Entwicklung von Mechanismen zur intelligenten Auswahl von Federated Learning Teilnehmern basierend auf Datenqualit√§t und Datenschutzanforderungen.\n‚Ä¢ Robust Aggregation: Implementierung Byzantine-fault-toleranter Aggregationsverfahren, die sowohl gegen b√∂swillige Teilnehmer als auch gegen Datenqualit√§tsprobleme robust sind.\n\nüîí Advanced Security Measures:\n‚Ä¢ Client Authentication: Robuste Authentifizierungssysteme f√ºr Federated Learning Teilnehmer mit Hardware-basierter Attestierung und Zero-Trust-Prinzipien.\n‚Ä¢ Communication Security: End-to-End-verschl√ºsselte Kommunikation zwischen allen Federated Learning Komponenten mit Perfect Forward Secrecy.\n‚Ä¢ Model Poisoning Defense: Entwicklung fortschrittlicher Erkennungs- und Abwehrmechanismen gegen Model Poisoning Angriffe in dezentralen Lernumgebungen.\n‚Ä¢ Gradient Privacy Protection: Spezielle Techniken zum Schutz vor Gradient-basierten Inference-Angriffen, die private Informationen aus Modell-Updates extrahieren k√∂nnten."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 7),
        question: 'Wie gew√§hrleistet ADVISORI die Anonymisierung und Pseudonymisierung von Daten f√ºr KI-Training und welche Techniken werden verwendet, um Re-Identifikationsrisiken zu minimieren?',
        answer: "Anonymisierung und Pseudonymisierung sind fundamentale S√§ulen des Datenschutzes in KI-Systemen, die jedoch bei unsachgem√§√üer Implementierung zu falscher Sicherheit f√ºhren k√∂nnen. ADVISORI entwickelt robuste Anonymisierungsstrategien, die nicht nur aktuellen Datenschutzanforderungen entsprechen, sondern auch gegen zuk√ºnftige Re-Identifikationsrisiken und fortschrittliche Deanonymisierungstechniken gewappnet sind.\n\nüé≠ Advanced Anonymization Techniques:\n‚Ä¢ K-Anonymity and Beyond: Implementierung von K-Anonymity, L-Diversity und T-Closeness Verfahren mit dynamischen Parametern, die sich an Datencharakteristika und Risikoprofile anpassen.\n‚Ä¢ Differential Privacy Application: Systematische Anwendung von Differential Privacy nicht nur auf Modellausgaben, sondern bereits auf Rohdaten vor der Anonymisierung f√ºr mathematisch garantierte Privatsph√§re.\n‚Ä¢ Synthetic Data Generation: Entwicklung fortschrittlicher Generative Adversarial Networks und Variational Autoencoders f√ºr die Erstellung synthetischer Datens√§tze, die statistische Eigenschaften bewahren, aber keine individuellen Informationen enthalten.\n‚Ä¢ Multi-Dimensional Generalization: Intelligente Generalisierung von Datenattributen basierend auf Sensitivit√§tsanalyse und Utility-Preservation-Algorithmen.\n\nüîç Re-Identification Risk Assessment:\n‚Ä¢ Linkage Attack Simulation: Systematische Simulation verschiedener Linkage-Attack-Szenarien unter Verwendung externer Datenquellen und √∂ffentlich verf√ºgbarer Informationen.\n‚Ä¢ Uniqueness Analysis: Fortlaufende Analyse der Eindeutigkeit von Datenkombinationen und automatische Anpassung von Anonymisierungsparametern bei erh√∂htem Re-Identifikationsrisiko.\n‚Ä¢ Temporal Privacy Protection: Ber√ºcksichtigung zeitlicher Aspekte bei der Anonymisierung, um Schutz vor longitudinalen Linkage-Angriffen zu gew√§hrleisten.\n‚Ä¢ Cross-Dataset Correlation Analysis: Bewertung von Re-Identifikationsrisiken durch Korrelation mit anderen verf√ºgbaren Datens√§tzen und √∂ffentlichen Informationsquellen.\n\nüõ°Ô∏è Robust Pseudonymization Infrastructure:\n‚Ä¢ Cryptographic Pseudonymization: Verwendung kryptographischer Hash-Funktionen und Salting-Verfahren f√ºr irreversible Pseudonymisierung mit regelm√§√üiger Schl√ºsselrotation.\n‚Ä¢ Format-Preserving Encryption: Implementierung von Verschl√ºsselungsverfahren, die Datenformate bewahren, w√§hrend sie starke Pseudonymisierung gew√§hrleisten.\n‚Ä¢ Tokenization Systems: Entwicklung sicherer Tokenization-Systeme mit Hardware Security Modules f√ºr hochsensible Identifikatoren.\n‚Ä¢ Multi-Layer Pseudonymization: Implementierung mehrschichtiger Pseudonymisierungsverfahren f√ºr verschiedene Sensitivit√§tsstufen und Anwendungskontexte."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 8),
        question: 'Welche Monitoring- und Audit-Systeme implementiert ADVISORI f√ºr kontinuierliche Datensicherheits√ºberwachung in KI-Umgebungen?',
        answer: "Kontinuierliche √úberwachung und Audit-Systeme sind essentiell f√ºr die Aufrechterhaltung der Datensicherheit in dynamischen KI-Umgebungen. ADVISORI entwickelt umfassende Monitoring-Infrastrukturen, die nicht nur Compliance gew√§hrleisten, sondern auch proaktiv Bedrohungen erkennen und automatisch auf Sicherheitsvorf√§lle reagieren, w√§hrend sie gleichzeitig vollst√§ndige Transparenz und Nachvollziehbarkeit aller Datenverarbeitungsaktivit√§ten bieten.\n\nüìä Comprehensive Monitoring Infrastructure:\n‚Ä¢ Real-Time Data Flow Monitoring: Kontinuierliche √úberwachung aller Datenfl√ºsse in ML-Pipelines mit automatischer Erkennung ungew√∂hnlicher Zugriffsmuster, Datenvolumen-Anomalien und verd√§chtiger Verarbeitungsaktivit√§ten.\n‚Ä¢ Model Behavior Analysis: Fortlaufende Analyse des Modellverhaltens zur Erkennung von Drift, Performance-Degradation oder Anzeichen f√ºr Kompromittierung durch adversarielle Angriffe.\n‚Ä¢ Privacy Compliance Monitoring: Automatisierte √úberwachung der Einhaltung von Datenschutzrichtlinien mit Real-Time-Alerts bei potenziellen Compliance-Verletzungen.\n‚Ä¢ Access Pattern Analysis: Intelligente Analyse von Zugriffmustern auf KI-Systeme und Daten zur Erkennung von Insider-Bedrohungen oder unauthorisierten Zugriffen.\n\nüîç Advanced Threat Detection:\n‚Ä¢ Anomaly Detection Systems: Implementierung Machine Learning-basierter Anomalieerkennung f√ºr die Identifikation ungew√∂hnlicher Aktivit√§ten in KI-Infrastrukturen.\n‚Ä¢ Behavioral Analytics: Entwicklung von Systemen zur Analyse des Nutzerverhaltens und automatischen Erkennung von Abweichungen von normalen Arbeitsmustern.\n‚Ä¢ Data Exfiltration Detection: Spezialisierte Systeme zur Erkennung von Datenabfluss-Versuchen, einschlie√ülich subtiler Angriffe √ºber Modellausgaben oder Seitenkanalangriffe.\n‚Ä¢ Adversarial Attack Detection: Real-Time-Erkennung von adversariellen Angriffen auf KI-Modelle durch Analyse von Input-Mustern und Modellresponse-Anomalien.\n\nüìã Comprehensive Audit Trail Systems:\n‚Ä¢ Immutable Audit Logs: Implementierung blockchain-basierter oder kryptographisch gesicherter Audit-Logs, die Manipulation verhindern und vollst√§ndige Nachvollziehbarkeit gew√§hrleisten.\n‚Ä¢ Data Lineage Tracking: Umfassende Verfolgung der Datenherkunft und -transformation durch alle Phasen des ML-Lebenszyklus f√ºr vollst√§ndige Transparenz.\n‚Ä¢ Decision Audit Trails: Detaillierte Protokollierung aller automatisierten Entscheidungen mit Kontext, verwendeten Daten und Entscheidungslogik f√ºr Compliance und Erkl√§rbarkeit.\n‚Ä¢ Compliance Reporting Automation: Automatisierte Generierung von Compliance-Berichten f√ºr verschiedene regulatorische Anforderungen mit Real-Time-Dashboards f√ºr Stakeholder."
      }
    ]
    
    // Update the document with new FAQs
    const updatedFaqs = [...(existingDoc.faq || []), ...newFaqs]
    
    console.log(`Adding ${newFaqs.length} new FAQs to the document...`)
    const transaction = client.transaction()
    transaction.patch(existingDoc._id, {
      set: {
        faq: updatedFaqs
      }
    })
    
    await transaction.commit()
    console.log('‚úÖ FAQs batch 2 added successfully')
  } catch (error) {
    console.error('Error:', error)
    throw error
  }
}

run()
