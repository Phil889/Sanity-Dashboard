import 'dotenv/config'
import { createClient } from '@sanity/client'

// Create client with direct credentials
const client = createClient({
  projectId: 'wwmm9rbb',
  dataset: 'production',
  apiVersion: '2024-02-14',
  token: process.env.SANITY_API_TOKEN,
  useCdn: false,
})

// Helper function to generate unique keys
function generateKey(prefix: string, index: number): string {
  return `${prefix}_${Date.now()}_${index}`
}

const run = async () => {
  try {
    console.log('Updating Beratung KI-Sicherheit page with FAQs batch 4...')
    
    // First, get the existing document
    console.log('Fetching existing document...')
    const existingDoc = await client.fetch('*[_id == $id][0]', { id: 'beratung-ki-sicherheit' })
    
    if (!existingDoc) {
      throw new Error('Document "beratung-ki-sicherheit" not found')
    }
    
    // Create new FAQs
    const newFaqs = [
      {
        _type: 'object',
        _key: generateKey('faq', 13),
        question: 'Wie k√∂nnen Unternehmen ihre AI-Teams und Mitarbeiter f√ºr Sicherheitsrisiken sensibilisieren und welche Schulungsans√§tze empfiehlt ADVISORI?',
        answer: "Human Factor Security ist ein kritischer, oft untersch√§tzter Aspekt der AI-Sicherheit, da selbst die fortschrittlichsten technischen Schutzma√ünahmen durch menschliche Fehler oder mangelndes Bewusstsein kompromittiert werden k√∂nnen. ADVISORI entwickelt umfassende AI-Security-Awareness-Programme, die sowohl technische Teams als auch Gesch√§ftsnutzer f√ºr die einzigartigen Sicherheitsherausforderungen von AI-Systemen sensibilisieren.\n\nüë• AI-Security Awareness Dimensionen:\n‚Ä¢ Technical Team Education: Spezialisierte Schulungen f√ºr Entwickler, Data Scientists und AI-Engineers √ºber sichere AI-Entwicklungspraktiken, Threat Modeling und Secure Coding f√ºr ML-Systeme.\n‚Ä¢ Business User Training: Sensibilisierung von Gesch√§ftsnutzern f√ºr AI-Sicherheitsrisiken, verantwortungsvolle AI-Nutzung und Erkennung verd√§chtiger AI-Verhaltensweisen.\n‚Ä¢ Executive Awareness: C-Level-Briefings √ºber strategische AI-Sicherheitsrisiken, Governance-Anforderungen und Investitionspriorit√§ten f√ºr AI-Security.\n‚Ä¢ Cross-Functional Collaboration: F√∂rderung der Zusammenarbeit zwischen Security-, AI- und Business-Teams f√ºr ganzheitliche Sicherheitskultur.\n\nüéì ADVISORI's Training Framework:\n‚Ä¢ Hands-On Security Labs: Praktische √úbungen mit realistischen AI-Sicherheitsszenarien, einschlie√ülich Adversarial Attack Simulations und Incident Response Drills.\n‚Ä¢ Role-Based Learning Paths: Ma√ügeschneiderte Lernpfade f√ºr verschiedene Rollen und Verantwortlichkeiten im AI-√ñkosystem des Unternehmens.\n‚Ä¢ Continuous Learning Programs: Etablierung kontinuierlicher Weiterbildungsprogramme, die mit der schnellen Entwicklung von AI-Sicherheitsbedrohungen Schritt halten.\n‚Ä¢ Security Culture Integration: Integration von AI-Sicherheitsbewusstsein in die Unternehmenskultur durch regelm√§√üige Kommunikation, Gamification und Incentive-Programme."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 14),
        question: 'Welche Herausforderungen entstehen bei der Sicherung von Edge AI und IoT-integrierten AI-Systemen und wie adressiert ADVISORI diese?',
        answer: "Edge AI und IoT-integrierte AI-Systeme stellen einzigartige Sicherheitsherausforderungen dar, da sie oft in ungesch√ºtzten Umgebungen operieren, begrenzte Rechenressourcen haben und schwer zu √ºberwachen sind. ADVISORI entwickelt spezialisierte Sicherheitsstrategien f√ºr Edge AI-Deployments, die sowohl die physischen als auch die digitalen Sicherheitsaspekte ber√ºcksichtigen.\n\nüåê Edge AI Security Challenges:\n‚Ä¢ Physical Security Constraints: Schutz von AI-Modellen und -Daten in physisch zug√§nglichen Edge-Ger√§ten, die Diebstahl, Manipulation oder Reverse Engineering ausgesetzt sein k√∂nnen.\n‚Ä¢ Resource-Constrained Security: Implementierung effektiver Sicherheitsma√ünahmen unter den Beschr√§nkungen von Rechenleistung, Speicher und Energieverbrauch von Edge-Ger√§ten.\n‚Ä¢ Distributed Attack Surface: Management der erweiterten Angriffsfl√§che durch Tausende oder Millionen von Edge-Ger√§ten mit AI-Funktionalit√§ten.\n‚Ä¢ Connectivity und Update Challenges: Sicherstellung sicherer Kommunikation und regelm√§√üiger Security Updates f√ºr Edge AI-Systeme mit intermittierender Konnektivit√§t.\n\nüîí ADVISORI's Edge AI Security Framework:\n‚Ä¢ Lightweight Security Protocols: Entwicklung ressourceneffizienter Sicherheitsprotokolle, die speziell f√ºr die Beschr√§nkungen von Edge AI-Ger√§ten optimiert sind.\n‚Ä¢ Hardware-Based Security: Integration von Hardware Security Modules und Trusted Execution Environments f√ºr Edge AI-Anwendungen.\n‚Ä¢ Federated Security Management: Implementierung dezentraler Sicherheitsmanagement-Ans√§tze, die lokale Autonomie mit zentraler √úberwachung und Kontrolle kombinieren.\n‚Ä¢ Resilient Edge Architectures: Entwicklung selbstheilender Edge AI-Systeme, die auch bei partiellen Kompromittierungen oder Ausf√§llen funktionsf√§hig bleiben."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 15),
        question: 'Wie k√∂nnen Unternehmen AI-Sicherheit in ihre bestehenden Security Operations Centers integrieren und welche Tools empfiehlt ADVISORI?',
        answer: "Die Integration von AI-Sicherheit in bestehende Security Operations Centers erfordert sowohl technologische Erweiterungen als auch organisatorische Anpassungen. AI-Systeme generieren einzigartige Security Events und erfordern spezialisierte Monitoring- und Response-F√§higkeiten. ADVISORI entwickelt ma√ügeschneiderte SOC-Integration-Strategien, die AI-Security nahtlos in bestehende Sicherheitsoperationen einbetten.\n\nüè¢ SOC Integration Challenges:\n‚Ä¢ AI-Specific Event Correlation: Entwicklung von Korrelationsregeln und Playbooks f√ºr AI-spezifische Security Events, die sich von traditionellen IT-Sicherheitsereignissen unterscheiden.\n‚Ä¢ Skill Gap Management: Aufbau von AI-Security-Expertise innerhalb bestehender SOC-Teams und Integration spezialisierter AI-Security-Analysten.\n‚Ä¢ Tool Integration: Nahtlose Integration von AI-Security-Tools in bestehende SIEM-, SOAR- und Threat Intelligence-Plattformen.\n‚Ä¢ Alert Fatigue Prevention: Intelligente Filterung und Priorisierung von AI-Security-Alerts zur Vermeidung von √úberlastung der SOC-Analysten.\n\nüõ†Ô∏è ADVISORI's SOC Enhancement Framework:\n‚Ä¢ AI-Aware SIEM Configuration: Anpassung bestehender SIEM-Systeme f√ºr die Erfassung, Analyse und Korrelation von AI-spezifischen Log-Daten und Security Events.\n‚Ä¢ Specialized AI Security Tools: Integration f√ºhrender AI-Security-L√∂sungen f√ºr Model Monitoring, Adversarial Attack Detection und AI Governance.\n‚Ä¢ Automated Response Orchestration: Entwicklung automatisierter Response-Workflows f√ºr h√§ufige AI-Sicherheitsvorf√§lle zur Entlastung der SOC-Teams.\n‚Ä¢ Threat Intelligence Enhancement: Erweiterung bestehender Threat Intelligence-Feeds um AI-spezifische Bedrohungsinformationen und Indicators of Compromise."
      },
      {
        _type: 'object',
        _key: generateKey('faq', 16),
        question: 'Welche Rolle spielt Privacy-Preserving AI bei der Sicherheitsstrategie und wie implementiert ADVISORI diese Technologien?',
        answer: "Privacy-Preserving AI ist nicht nur eine Compliance-Anforderung, sondern ein fundamentaler Sicherheitsbaustein, der es erm√∂glicht, die Vorteile der KI zu nutzen, ohne sensible Daten zu gef√§hrden. ADVISORI implementiert fortschrittliche Privacy-Preserving-Technologien, die sowohl Datenschutz als auch AI-Performance optimieren und gleichzeitig neue Sicherheitsdimensionen erschlie√üen.\n\nüîê Privacy-Preserving AI Technologies:\n‚Ä¢ Differential Privacy: Implementierung mathematischer Garantien f√ºr Datenschutz, die es erm√∂glichen, n√ºtzliche Insights aus Daten zu gewinnen, ohne individuelle Datenpunkte preiszugeben.\n‚Ä¢ Federated Learning: Entwicklung dezentraler Lernans√§tze, bei denen AI-Modelle trainiert werden, ohne dass sensible Daten das lokale Umfeld verlassen m√ºssen.\n‚Ä¢ Homomorphic Encryption: Einsatz von Verschl√ºsselungstechnologien, die Berechnungen auf verschl√ºsselten Daten erm√∂glichen, ohne diese zu entschl√ºsseln.\n‚Ä¢ Secure Multi-Party Computation: Implementierung von Protokollen, die es mehreren Parteien erm√∂glichen, gemeinsam AI-Modelle zu trainieren, ohne ihre Daten zu teilen.\n\nüõ°Ô∏è ADVISORI's Privacy-First AI Architecture:\n‚Ä¢ Privacy Budget Management: Systematische Verwaltung von Privacy-Budgets in Differential Privacy-Systemen zur Optimierung des Trade-offs zwischen Datenschutz und Modellgenauigkeit.\n‚Ä¢ Secure Aggregation Protocols: Entwicklung sicherer Aggregationsverfahren f√ºr Federated Learning, die sowohl gegen externe Angriffe als auch gegen malicious Participants sch√ºtzen.\n‚Ä¢ Privacy-Preserving Model Sharing: Implementierung sicherer Verfahren f√ºr das Teilen von AI-Modellen zwischen Organisationen, ohne sensible Trainingsdaten preiszugeben.\n‚Ä¢ Continuous Privacy Monitoring: Etablierung kontinuierlicher √úberwachung der Privacy-Garantien in produktiven AI-Systemen zur Sicherstellung dauerhafter Datenschutz-Compliance."
      }
    ]
    
    // Update the document with new FAQs
    const updatedFaqs = [...(existingDoc.faq || []), ...newFaqs]
    
    console.log(`Adding ${newFaqs.length} new FAQs to the document...`)
    const transaction = client.transaction()
    transaction.patch(existingDoc._id, {
      set: {
        faq: updatedFaqs
      }
    })
    
    await transaction.commit()
    console.log('‚úÖ FAQs batch 4 added successfully')
  } catch (error) {
    console.error('Error:', error)
    throw error
  }
}

run()
