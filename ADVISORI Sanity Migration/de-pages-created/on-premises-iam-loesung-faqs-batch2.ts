import 'dotenv/config'
import { createClient } from '@sanity/client'

// Create client with direct credentials
const client = createClient({
  projectId: 'wwmm9rbb',
  dataset: 'production',
  apiVersion: '2024-02-14',
  token: process.env.SANITY_API_TOKEN,
  useCdn: false,
})

// Helper function to generate unique keys
function generateKey(prefix: string, index: number): string {
  return `${prefix}_${Date.now()}_${index}`
}

const run = async () => {
  try {
    console.log('Updating On-Premises IAM-L√∂sung page with FAQ batch 2...')
    
    // First, get the existing document
    console.log('Fetching existing document...')
    const existingDoc = await client.fetch('*[_id == $id][0]', { id: 'on-premises-iam-loesung' })
    
    if (!existingDoc) {
      throw new Error('Document "on-premises-iam-loesung" not found')
    }
    
    // Create new FAQs for On-Premises IAM implementation and operations
    const newFaqs = [
      {
        _type: 'object',
        _key: generateKey('faq', 5),
        question: 'Wie gew√§hrleistet man Hochverf√ºgbarkeit und Disaster Recovery f√ºr kritische On-Premises IAM-Systeme ohne Kompromittierung der Sicherheit oder Performance?',
        answer: "Hochverf√ºgbarkeit und Disaster Recovery f√ºr On-Premises IAM-Systeme erfordern eine durchdachte Architektur, die Redundanz, geografische Verteilung und automatisierte Failover-Mechanismen intelligent kombiniert. Diese kritischen Systeme m√ºssen kontinuierliche Verf√ºgbarkeit gew√§hrleisten, da Ausf√§lle sofortige Auswirkungen auf alle Gesch√§ftsprozesse haben k√∂nnen.\n\nüèóÔ∏è Redundante Architektur-Design:\n‚Ä¢ Multi-Site-Deployment mit geografisch verteilten Rechenzentren f√ºr maximale Ausfallsicherheit\n‚Ä¢ Active-Active-Konfigurationen mit Load Balancing und automatischem Failover zwischen Standorten\n‚Ä¢ Database Clustering mit synchroner Replikation f√ºr konsistente Datenintegrit√§t\n‚Ä¢ Network-Level Redundancy mit mehreren Internet-Providern und Backup-Verbindungen\n‚Ä¢ Hardware-Redundanz auf allen kritischen Komponenten einschlie√ülich Storage, Compute und Netzwerk\n\n‚ö° Automated Failover und Recovery:\n‚Ä¢ Intelligent Health Monitoring mit Real-time System-Status-√úberwachung und Anomaly Detection\n‚Ä¢ Automated Failover Procedures mit definierten Recovery Time Objectives und Recovery Point Objectives\n‚Ä¢ Graceful Degradation Strategies f√ºr partielle Service-Verf√ºgbarkeit w√§hrend Wartungsarbeiten\n‚Ä¢ Automated Rollback Capabilities f√ºr schnelle Wiederherstellung bei fehlgeschlagenen Updates\n‚Ä¢ Continuous Data Synchronization zwischen prim√§ren und sekund√§ren Standorten\n\nüîÑ Comprehensive Backup und Recovery:\n‚Ä¢ Multi-Tier Backup Strategy mit lokalen, regionalen und geografisch verteilten Backup-Standorten\n‚Ä¢ Point-in-Time Recovery Capabilities f√ºr granulare Wiederherstellung spezifischer Zeitpunkte\n‚Ä¢ Encrypted Backup Storage mit sicherer Schl√ºsselverwaltung und Access Controls\n‚Ä¢ Regular Recovery Testing mit dokumentierten Procedures und Performance-Validierung\n‚Ä¢ Incremental und Differential Backup-Strategien f√ºr optimierte Storage-Nutzung\n\nüîç Proactive Monitoring und Alerting:\n‚Ä¢ Comprehensive System Monitoring mit Performance-Metriken, Capacity-Tracking und Trend-Analyse\n‚Ä¢ Intelligent Alerting Systems mit Escalation-Procedures und Automated Response-Capabilities\n‚Ä¢ Predictive Analytics f√ºr fr√ºhzeitige Erkennung potenzieller Systemprobleme\n‚Ä¢ Real-time Dashboard mit Executive-Level Visibility in System-Status und Performance\n‚Ä¢ Integration mit Enterprise Monitoring Tools f√ºr zentrale √úberwachung aller kritischen Systeme\n\nüìã Business Continuity Planning:\n‚Ä¢ Comprehensive Disaster Recovery Plans mit definierten Rollen, Verantwortlichkeiten und Procedures\n‚Ä¢ Regular DR Testing und Simulation mit dokumentierten Ergebnissen und Improvement-Ma√ünahmen\n‚Ä¢ Communication Plans f√ºr Stakeholder-Benachrichtigung und Status-Updates w√§hrend Incidents\n‚Ä¢ Vendor Management f√ºr kritische Hardware- und Software-Support w√§hrend Notf√§llen\n‚Ä¢ Documentation Management mit aktuellen System-Konfigurationen und Recovery-Procedures\n\nüõ°Ô∏è Security-First Recovery Approach:\n‚Ä¢ Secure Recovery Procedures mit Authentifizierung und Autorisierung aller Recovery-Aktivit√§ten\n‚Ä¢ Integrity Verification f√ºr alle wiederhergestellten Daten und Systemkonfigurationen\n‚Ä¢ Forensic Capabilities f√ºr Incident Analysis und Root Cause Determination\n‚Ä¢ Secure Communication Channels f√ºr alle Disaster Recovery Koordination\n‚Ä¢ Compliance Validation f√ºr alle Recovery-Prozesse und Dokumentations-Anforderungen"
      },
      {
        _type: 'object',
        _key: generateKey('faq', 6),
        question: 'Welche Performance-Optimierungsstrategien sind f√ºr gro√üe On-Premises IAM-Deployments mit Millionen von Benutzern und komplexen Autorisierungsanforderungen erforderlich?',
        answer: "Performance-Optimierung f√ºr gro√üe On-Premises IAM-Deployments erfordert einen vielschichtigen Ansatz, der Architektur-Design, Datenbank-Optimierung, Caching-Strategien und intelligente Load-Distribution kombiniert. Diese Systeme m√ºssen Sub-Sekunden-Response-Zeiten f√ºr Authentifizierung und Autorisierung gew√§hrleisten, w√§hrend sie gleichzeitig komplexe Policy-Evaluationen und umfangreiche Audit-Logging bew√§ltigen.\n\nüöÄ Scalable Architecture Patterns:\n‚Ä¢ Microservices-basierte Architektur mit unabh√§ngig skalierbaren Service-Komponenten\n‚Ä¢ Horizontal Scaling mit Auto-Scaling-Capabilities basierend auf Load-Metriken\n‚Ä¢ Distributed Caching mit Redis oder Hazelcast f√ºr h√§ufig abgerufene Identit√§tsdaten\n‚Ä¢ API Gateway mit Rate Limiting und Request Routing f√ºr optimale Resource-Utilization\n‚Ä¢ Event-driven Architecture f√ºr asynchrone Verarbeitung nicht-kritischer Operationen\n\nüíæ Database Performance Optimization:\n‚Ä¢ Database Partitioning und Sharding f√ºr optimale Query-Performance bei gro√üen Datenmengen\n‚Ä¢ Index Optimization mit regelm√§√üiger Analyse und Tuning f√ºr h√§ufige Query-Patterns\n‚Ä¢ Connection Pooling mit optimierten Pool-Gr√∂√üen f√ºr maximale Durchsatz-Effizienz\n‚Ä¢ Read Replicas f√ºr Load-Distribution zwischen Read- und Write-Operationen\n‚Ä¢ Query Optimization mit Execution Plan Analysis und Performance-Tuning\n\n‚ö° Intelligent Caching Strategies:\n‚Ä¢ Multi-Level Caching mit Application-Level, Database-Level und Network-Level Caching\n‚Ä¢ Smart Cache Invalidation mit Event-based Updates f√ºr Daten-Konsistenz\n‚Ä¢ Session Caching f√ºr h√§ufige Benutzer-Authentifizierungen und Token-Validierung\n‚Ä¢ Policy Caching f√ºr komplexe Autorisierungsregeln mit Lazy Loading\n‚Ä¢ Distributed Cache Synchronization f√ºr Multi-Site-Deployments\n\nüîÑ Load Balancing und Traffic Management:\n‚Ä¢ Intelligent Load Balancing mit Session Affinity und Health-based Routing\n‚Ä¢ Geographic Load Distribution f√ºr optimale Latenz basierend auf Benutzer-Standorten\n‚Ä¢ Circuit Breaker Patterns f√ºr Resilience gegen Service-Degradation\n‚Ä¢ Request Queuing und Throttling f√ºr Schutz vor Traffic-Spitzen\n‚Ä¢ Adaptive Routing basierend auf Real-time Performance-Metriken\n\nüìä Performance Monitoring und Analytics:\n‚Ä¢ Real-time Performance Monitoring mit Sub-Second Granularit√§t f√ºr kritische Metriken\n‚Ä¢ Application Performance Management mit End-to-End Transaction Tracing\n‚Ä¢ Capacity Planning mit Predictive Analytics f√ºr zuk√ºnftige Skalierungsanforderungen\n‚Ä¢ User Experience Monitoring mit Response-Time-Tracking f√ºr verschiedene Benutzergruppen\n‚Ä¢ Bottleneck Identification mit automatisierten Performance-Analysen\n\nüîß Advanced Optimization Techniques:\n‚Ä¢ Lazy Loading f√ºr nicht-kritische Datenelemente mit On-Demand-Retrieval\n‚Ä¢ Batch Processing f√ºr Bulk-Operationen mit optimierten Verarbeitungszeiten\n‚Ä¢ Asynchronous Processing f√ºr zeitaufw√§ndige Operationen ohne User-Impact\n‚Ä¢ Memory Optimization mit Garbage Collection Tuning und Memory Pool Management\n‚Ä¢ Network Optimization mit Compression und Protocol-Tuning f√ºr minimale Latenz"
      },
      {
        _type: 'object',
        _key: generateKey('faq', 7),
        question: 'Wie implementiert man sichere Hybrid-Architekturen f√ºr On-Premises IAM-Systeme mit selektiver Cloud-Integration ohne Kompromittierung der Sicherheitsstandards?',
        answer: "Sichere Hybrid-Architekturen f√ºr On-Premises IAM-Systeme erm√∂glichen es Unternehmen, die Vorteile cloud-basierter Services zu nutzen, w√§hrend kritische Identit√§tsdaten und Kernfunktionen lokal verbleiben. Diese Architekturen erfordern sophisticated Security-Controls, intelligente Data Classification und robuste Integration-Patterns f√ºr nahtlose Interoperabilit√§t.\n\nüîê Security-First Hybrid Design:\n‚Ä¢ Data Classification Framework mit klarer Trennung zwischen kritischen und nicht-kritischen Identit√§tsdaten\n‚Ä¢ Zero-Trust Network Architecture mit kontinuierlicher Verifikation aller Hybrid-Verbindungen\n‚Ä¢ End-to-End Encryption f√ºr alle Cloud-Kommunikation mit Hardware-Security-Module-Integration\n‚Ä¢ Secure Tunneling mit VPN oder Private Connectivity f√ºr alle Hybrid-Datenfl√ºsse\n‚Ä¢ Multi-Factor Authentication f√ºr alle Cloud-Service-Zugriffe mit Hardware-Token-Unterst√ºtzung\n\nüåê Intelligent Service Distribution:\n‚Ä¢ Core Identity Services bleiben On-Premises f√ºr maximale Kontrolle und Compliance\n‚Ä¢ Non-Critical Services wie Analytics oder Reporting k√∂nnen selektiv in die Cloud migriert werden\n‚Ä¢ Hybrid Identity Federation mit SAML oder OAuth f√ºr sichere Cross-Domain-Authentication\n‚Ä¢ API Gateway als Secure Proxy f√ºr alle Cloud-Service-Integrationen\n‚Ä¢ Service Mesh Architecture f√ºr sichere Service-to-Service-Kommunikation\n\nüîÑ Secure Data Synchronization:\n‚Ä¢ Selective Data Replication mit Encryption-at-Rest und Encryption-in-Transit\n‚Ä¢ Real-time Synchronization f√ºr kritische Identit√§ts√§nderungen mit Conflict Resolution\n‚Ä¢ Batch Synchronization f√ºr nicht-kritische Daten mit optimierten Transfer-Windows\n‚Ä¢ Data Residency Controls mit geografischen Beschr√§nkungen f√ºr sensitive Daten\n‚Ä¢ Audit Trail Synchronization f√ºr umfassende Compliance-Nachverfolgung\n\nüõ°Ô∏è Advanced Security Controls:\n‚Ä¢ Network Segmentation mit Micro-Perimeters f√ºr jede Hybrid-Integration\n‚Ä¢ Intrusion Detection Systems mit spezieller √úberwachung f√ºr Hybrid-Traffic\n‚Ä¢ Data Loss Prevention mit Content Inspection f√ºr alle Cloud-bound Datenfl√ºsse\n‚Ä¢ Behavioral Analytics f√ºr Anomaly Detection in Hybrid-Umgebungen\n‚Ä¢ Continuous Security Assessment mit automatisierten Vulnerability Scans\n\nüìã Governance und Compliance:\n‚Ä¢ Unified Policy Management f√ºr konsistente Sicherheitsrichtlinien √ºber alle Umgebungen\n‚Ä¢ Compliance Mapping mit klarer Zuordnung regulatorischer Anforderungen zu Deployment-Modellen\n‚Ä¢ Risk Assessment Framework f√ºr kontinuierliche Bewertung von Hybrid-Risiken\n‚Ä¢ Vendor Management mit Due Diligence f√ºr alle Cloud-Service-Provider\n‚Ä¢ Incident Response Procedures mit koordinierten Prozessen f√ºr Hybrid-Incidents\n\n‚öôÔ∏è Operational Excellence:\n‚Ä¢ Unified Monitoring mit Single-Pane-of-Glass f√ºr alle Hybrid-Komponenten\n‚Ä¢ Automated Deployment mit Infrastructure-as-Code f√ºr konsistente Konfigurationen\n‚Ä¢ Disaster Recovery Coordination zwischen On-Premises und Cloud-Komponenten\n‚Ä¢ Performance Optimization mit Load Balancing zwischen lokalen und Cloud-Services\n‚Ä¢ Cost Optimization mit intelligenter Workload-Placement basierend auf Kosten-Nutzen-Analysen"
      },
      {
        _type: 'object',
        _key: generateKey('faq', 8),
        question: 'Welche spezifischen Herausforderungen entstehen bei der Migration von Legacy-IAM-Systemen zu modernen On-Premises-L√∂sungen und wie bew√§ltigt man diese erfolgreich?',
        answer: "Die Migration von Legacy-IAM-Systemen zu modernen On-Premises-L√∂sungen ist eine der komplexesten IT-Transformationen, da sie kritische Gesch√§ftsprozesse, Sicherheitskontrollen und Benutzerworkflows gleichzeitig betrifft. Diese Projekte erfordern sorgf√§ltige Planung, Risikomanagement und phasenweise Implementierung f√ºr erfolgreiche Transformation ohne Gesch√§ftsunterbrechung.\n\nüîç Comprehensive Legacy Assessment:\n‚Ä¢ Detailed System Inventory mit vollst√§ndiger Dokumentation aller Legacy-Komponenten und Abh√§ngigkeiten\n‚Ä¢ Data Quality Assessment f√ºr Identit√§tsdaten mit Bereinigung und Standardisierung\n‚Ä¢ Security Gap Analysis zur Identifikation von Schwachstellen und Compliance-Defiziten\n‚Ä¢ Performance Baseline Establishment f√ºr Vergleich mit neuen Systemen\n‚Ä¢ Business Process Mapping f√ºr Verst√§ndnis aktueller Workflows und Benutzerinteraktionen\n\n‚ö° Risk Mitigation Strategies:\n‚Ä¢ Parallel System Operation mit schrittweiser Benutzer-Migration f√ºr minimales Risiko\n‚Ä¢ Comprehensive Backup und Rollback Procedures f√ºr jeden Migrationschritt\n‚Ä¢ Pilot Group Testing mit ausgew√§hlten Benutzern vor Full-Scale-Rollout\n‚Ä¢ Automated Testing Frameworks f√ºr kontinuierliche Validierung der Migrationsergebnisse\n‚Ä¢ Emergency Procedures f√ºr schnelle Wiederherstellung bei kritischen Problemen\n\nüîÑ Phased Migration Approach:\n‚Ä¢ Infrastructure Migration mit Aufbau der neuen Plattform parallel zu Legacy-Systemen\n‚Ä¢ Data Migration mit ETL-Prozessen f√ºr sichere und vollst√§ndige Daten√ºbertragung\n‚Ä¢ Application Integration mit schrittweiser Anbindung von Anwendungen an neue IAM-Services\n‚Ä¢ User Migration mit Gruppen-basiertem Rollout und kontinuierlichem Support\n‚Ä¢ Legacy System Decommissioning mit sicherer Datenarchivierung und Asset-Disposal\n\nüõ†Ô∏è Technical Implementation Challenges:\n‚Ä¢ Protocol Translation f√ºr Kompatibilit√§t zwischen Legacy- und modernen Authentifizierungsprotokollen\n‚Ä¢ Data Format Conversion mit Mapping zwischen verschiedenen Identit√§tsdatenstrukturen\n‚Ä¢ Custom Integration Development f√ºr spezielle Legacy-Anwendungen ohne Standard-Protokolle\n‚Ä¢ Performance Optimization f√ºr neue Systeme basierend auf Legacy-Workload-Patterns\n‚Ä¢ Security Enhancement mit Implementation moderner Sicherheitskontrollen\n\nüë• Change Management und User Adoption:\n‚Ä¢ Comprehensive Training Programs f√ºr IT-Teams und End-Users\n‚Ä¢ Communication Strategy mit transparenter Information √ºber √Ñnderungen und Vorteile\n‚Ä¢ Support Structure mit Help Desk und Escalation-Procedures w√§hrend der Migration\n‚Ä¢ User Experience Optimization f√ºr minimale Disruption bestehender Workflows\n‚Ä¢ Feedback Collection und Continuous Improvement basierend auf User-Input\n\nüìä Success Measurement und Optimization:\n‚Ä¢ Migration Progress Tracking mit detaillierten Metriken und Milestone-Monitoring\n‚Ä¢ Performance Comparison zwischen Legacy- und neuen Systemen\n‚Ä¢ User Satisfaction Surveys f√ºr Bewertung der Migration-Erfahrung\n‚Ä¢ Security Posture Assessment f√ºr Validierung verbesserter Sicherheitskontrollen\n‚Ä¢ ROI Analysis f√ºr Bewertung der Business-Benefits der Migration"
      }
    ]
    
    // Update the document with new FAQs
    const updatedFaqs = [...(existingDoc.faq || []), ...newFaqs]
    
    console.log(`Adding ${newFaqs.length} new FAQs to the document...`)
    const transaction = client.transaction()
    transaction.patch(existingDoc._id, {
      set: {
        faq: updatedFaqs
      }
    })
    
    await transaction.commit()
    console.log('‚úÖ FAQ batch 2 added successfully')
  } catch (error) {
    console.error('Error:', error)
    throw error
  }
}

run()
